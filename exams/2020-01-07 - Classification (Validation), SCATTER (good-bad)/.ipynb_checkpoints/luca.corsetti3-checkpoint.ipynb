{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b8734185-6e9f-43a6-8c7e-6e9318b649f7",
   "metadata": {},
   "source": [
    "# Machine Learning - Python Lab Exam â€“ 07-01-2020"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b29f9b8d-6944-4615-867f-400fb20fa7a5",
   "metadata": {},
   "source": [
    "Fit a classifier for the included dataset.\n",
    "The solution must be produced as a Python Notebook.\n",
    "The notebook must include appropriate comments and must produce:\n",
    "1. a pairplot of the data (see Seaborn pairplot) and a comment on remarkable situations, if\n",
    "any (5pt)\n",
    "2. a classification model using a method of your choice with the schema \"train-validationtest\" exploring an appropriate range of parameter values (5pt)\n",
    "3. the optimal parameter(s) (5pt)\n",
    "4. a scatter plot of the test set using a pair of attributes of your choice with the class as\n",
    "colour (5pt)\n",
    "5. ... and the good/bad prediction as the point style (5pt)\n",
    "1. hint: the seaborn scatterplot function allows a \"style\" parameter which is a vector\n",
    "of values; this can be obtained as a comparison between the true and the\n",
    "predicted target in the test set, see\n",
    "https://seaborn.pydata.org/generated/seaborn.scatterplot.html\n",
    "\n",
    "\n",
    "Quality of the code (6pt):\n",
    "1. The python cells must be preceded by appropriate comments\n",
    "2. Useless cells and pieces of code will be penalised\n",
    "3. Naming style of variables must be uniform and in English\n",
    "4. Bad indentation and messy code will be penalised"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55883959-4a19-4c6b-9d05-c0009a7a072f",
   "metadata": {},
   "source": [
    "## 1. a pairplot of the data (see Seaborn pairplot) and a comment on remarkable situations, if any (5pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d3c2a47-cd15-4e3d-96df-1936aa877623",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "random_state=55\n",
    "\n",
    "target = 'Class'\n",
    "\n",
    "np.random.seed(random_state)\n",
    "df = pd.read_csv('./exam_2020_01_07_data.csv')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "203f641e-e831-480b-af78-ff18f3287eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cff551a2-cfeb-448d-a7fd-911c04fe9552",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(df, hue='Class')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9bf3b04-0942-4306-a57a-c87f33274319",
   "metadata": {},
   "source": [
    "nothing noticeable can be underline about the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "696375b0-4ca2-4d1d-b163-c4d8023282d2",
   "metadata": {},
   "source": [
    "## 2. a classification model using a method of your choice with the schema \"train-validationtest\" exploring an appropriate range of parameter values (5pt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "622c35e0-56fc-47c2-a790-9e635cbcb28e",
   "metadata": {},
   "source": [
    "We will use a **Decision Tree** classifier.\\\n",
    "Firstly we divide the target column from the rest of the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "781e53b4-0b20-4f69-8b1f-0d7f7b83b531",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=[target])\n",
    "y = df[target]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbc78bdc-1449-4a22-b4cd-eb575cf51722",
   "metadata": {},
   "source": [
    "We then divide the data in two, one for training the classifier and the other to test it after the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d460b375-1454-4626-8351-2081a36c594b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=2/3)\n",
    "\n",
    "print(f\"there are {X_train.shape[0]} training samples\")\n",
    "print(f\"there are {X_test.shape[0]} test samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d64d91bb-8606-4bee-8388-6ce65d99e027",
   "metadata": {},
   "source": [
    "We then instantiate the classifier and fit it (train) on the training data previously split.\\\n",
    "\n",
    "When done we predict the classifier over the training data using the **accuracy_score** function. We expect an accuracy of 100%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b6923e5-fea4-4bd4-976e-c96ed500e53b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "estimator = DecisionTreeClassifier(criterion='entropy', random_state=random_state)\n",
    "estimator.fit(X_train, y_train)\n",
    "\n",
    "y_pred_train = estimator.predict(X_train)\n",
    "scoring = accuracy_score(y_train, y_pred_train) * 100\n",
    "\n",
    "print(f\"the accuracy on the training set is: {scoring:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7f3e121-e443-4052-9cab-f13f2262d145",
   "metadata": {},
   "source": [
    "We should now try to predict the target over the test set and evaluate its accuracy score. This ensures a more meaningful measurement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e81389f-950e-4e4e-b972-29667f14c1bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test = estimator.predict(X_test)\n",
    "scoring = accuracy_score(y_test, y_pred_test) * 100\n",
    "\n",
    "print(f\"the accuracy on the test set is: {scoring:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1718a12-818f-4c4c-9cec-bfd914a96450",
   "metadata": {},
   "source": [
    "The task requires us to use the train-validationtest schema, so we will split again the test data to obtain a validation and a test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "335e8b7b-fa1c-425f-a242-5b79d75db134",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, train_size=2/3, random_state=random_state)\n",
    "\n",
    "print(f\"there are {X_val.shape[0]} validation samples in the set\")\n",
    "print(f\"there are {X_test.shape[0]} test samples in the set\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
