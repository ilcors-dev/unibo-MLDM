{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Alessandro Pomponio - 0000920265"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. The data are split in two files, load the files and merge them\n",
    "according to the first column, which is the index; both the files\n",
    "contain a \"class\" column, keep both the columns in the merged\n",
    "file calling them \"class_x\" and \"class_y\" (you can use the merge\n",
    "function of pandas dataframes) (4pt)\n",
    "2. Delete all the rows where class_x is different from class_y, then\n",
    "drop class_y and rename class_x as class (4pt)\n",
    "3. Reorder the columns in alphabetical order, but placing the class\n",
    "column as the last one; the cleaned dataframe must be named\n",
    "df; show its size and head (4pt)\n",
    "4. Find the best classification scheme using three classification\n",
    "methods\n",
    "5. For each classification method find the best parameter setting\n",
    "with cross validation on the training set (6pt)\n",
    "6. For each classification method compute the accuracy and the\n",
    "confusion matrix on the test set (4pt)\n",
    "7. Produce a plot of the accuracies given by the methods\n",
    "attempted (3pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Variables\n",
    "first_file_name = 'exam_1.csv'\n",
    "second_file_name = 'exam_2.csv'\n",
    "separator = ','\n",
    "random_state = 42\n",
    "\n",
    "# Directives\n",
    "%matplotlib inline\n",
    "np.random.seed(random_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. The data are split in two files, load the files and merge them according to the first column, which is the index; both the files contain a \"class\" column, keep both the columns in the merged file calling them \"class_x\" and \"class_y\" (you can use the merge function of pandas dataframes) (4pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the first file\n",
    "first_df = pd.read_csv(first_file_name, delimiter = separator, index_col = 0)\n",
    "\n",
    "# Load the second file\n",
    "second_df = pd.read_csv(second_file_name, delimiter = separator, index_col = 0)\n",
    "\n",
    "# Merge the two dataframes with the 'outer' how, as to perform a SQL-like full outer join\n",
    "# on the two indexes, adding suffixes as requested (default option)\n",
    "df = first_df.merge(second_df, how = 'outer', left_index = True, right_index = True, suffixes = ('_x', '_y'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>C</th>\n",
       "      <th>E</th>\n",
       "      <th>class_x</th>\n",
       "      <th>B</th>\n",
       "      <th>D</th>\n",
       "      <th>F</th>\n",
       "      <th>class_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.386248</td>\n",
       "      <td>1.536628</td>\n",
       "      <td>1.232589</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.432057</td>\n",
       "      <td>1.039420</td>\n",
       "      <td>0.280469</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-2.686649</td>\n",
       "      <td>4.640702</td>\n",
       "      <td>0.823433</td>\n",
       "      <td>1</td>\n",
       "      <td>-4.036329</td>\n",
       "      <td>0.526320</td>\n",
       "      <td>-0.419013</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.474124</td>\n",
       "      <td>1.576616</td>\n",
       "      <td>-1.256234</td>\n",
       "      <td>0</td>\n",
       "      <td>0.179770</td>\n",
       "      <td>0.157974</td>\n",
       "      <td>-0.162869</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.343790</td>\n",
       "      <td>-0.514008</td>\n",
       "      <td>1.520392</td>\n",
       "      <td>2</td>\n",
       "      <td>-1.299109</td>\n",
       "      <td>-0.152250</td>\n",
       "      <td>0.045123</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-2.187600</td>\n",
       "      <td>0.289041</td>\n",
       "      <td>1.318321</td>\n",
       "      <td>2</td>\n",
       "      <td>-2.089699</td>\n",
       "      <td>-0.494995</td>\n",
       "      <td>-0.661858</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>-1.668710</td>\n",
       "      <td>1.258125</td>\n",
       "      <td>-1.111517</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.114765</td>\n",
       "      <td>-1.209808</td>\n",
       "      <td>1.546161</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>0.842932</td>\n",
       "      <td>-0.862210</td>\n",
       "      <td>-0.658845</td>\n",
       "      <td>2</td>\n",
       "      <td>1.188689</td>\n",
       "      <td>-0.174914</td>\n",
       "      <td>-1.376579</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>1.371652</td>\n",
       "      <td>0.861149</td>\n",
       "      <td>-0.966656</td>\n",
       "      <td>0</td>\n",
       "      <td>0.929550</td>\n",
       "      <td>0.616987</td>\n",
       "      <td>-0.643962</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>2.091386</td>\n",
       "      <td>-0.164420</td>\n",
       "      <td>-1.185916</td>\n",
       "      <td>0</td>\n",
       "      <td>1.918095</td>\n",
       "      <td>0.557593</td>\n",
       "      <td>-0.942563</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>-0.460456</td>\n",
       "      <td>1.498658</td>\n",
       "      <td>1.349191</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.513903</td>\n",
       "      <td>1.046225</td>\n",
       "      <td>-0.666189</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             A         C         E  class_x         B         D         F  \\\n",
       "0    -0.386248  1.536628  1.232589        1 -1.432057  1.039420  0.280469   \n",
       "1    -2.686649  4.640702  0.823433        1 -4.036329  0.526320 -0.419013   \n",
       "2     0.474124  1.576616 -1.256234        0  0.179770  0.157974 -0.162869   \n",
       "3    -1.343790 -0.514008  1.520392        2 -1.299109 -0.152250  0.045123   \n",
       "4    -2.187600  0.289041  1.318321        2 -2.089699 -0.494995 -0.661858   \n",
       "...        ...       ...       ...      ...       ...       ...       ...   \n",
       "1995 -1.668710  1.258125 -1.111517        0 -1.114765 -1.209808  1.546161   \n",
       "1996  0.842932 -0.862210 -0.658845        2  1.188689 -0.174914 -1.376579   \n",
       "1997  1.371652  0.861149 -0.966656        0  0.929550  0.616987 -0.643962   \n",
       "1998  2.091386 -0.164420 -1.185916        0  1.918095  0.557593 -0.942563   \n",
       "1999 -0.460456  1.498658  1.349191        1 -1.513903  1.046225 -0.666189   \n",
       "\n",
       "      class_y  \n",
       "0           1  \n",
       "1           1  \n",
       "2           0  \n",
       "3           2  \n",
       "4           2  \n",
       "...       ...  \n",
       "1995        0  \n",
       "1996        2  \n",
       "1997        0  \n",
       "1998        0  \n",
       "1999        1  \n",
       "\n",
       "[2000 rows x 8 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Delete all the rows where class_x is different from class_y, then drop class_y and rename class_x as class (4pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find all the indexes of the rows where class_x is different from class_y\n",
    "indexes_to_delete = df[df['class_x'] != df['class_y']].index\n",
    "\n",
    "# Drop those rows from the dataframe\n",
    "df = df.drop(index = indexes_to_delete, axis = 0)\n",
    "\n",
    "# Drop class_y\n",
    "df = df.drop(columns = 'class_y', axis = 1)\n",
    "\n",
    "# Rename class_x as class\n",
    "df = df.rename(columns = {'class_x': 'class'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>C</th>\n",
       "      <th>E</th>\n",
       "      <th>class</th>\n",
       "      <th>B</th>\n",
       "      <th>D</th>\n",
       "      <th>F</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.386248</td>\n",
       "      <td>1.536628</td>\n",
       "      <td>1.232589</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.432057</td>\n",
       "      <td>1.039420</td>\n",
       "      <td>0.280469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-2.686649</td>\n",
       "      <td>4.640702</td>\n",
       "      <td>0.823433</td>\n",
       "      <td>1</td>\n",
       "      <td>-4.036329</td>\n",
       "      <td>0.526320</td>\n",
       "      <td>-0.419013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.474124</td>\n",
       "      <td>1.576616</td>\n",
       "      <td>-1.256234</td>\n",
       "      <td>0</td>\n",
       "      <td>0.179770</td>\n",
       "      <td>0.157974</td>\n",
       "      <td>-0.162869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.343790</td>\n",
       "      <td>-0.514008</td>\n",
       "      <td>1.520392</td>\n",
       "      <td>2</td>\n",
       "      <td>-1.299109</td>\n",
       "      <td>-0.152250</td>\n",
       "      <td>0.045123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-2.187600</td>\n",
       "      <td>0.289041</td>\n",
       "      <td>1.318321</td>\n",
       "      <td>2</td>\n",
       "      <td>-2.089699</td>\n",
       "      <td>-0.494995</td>\n",
       "      <td>-0.661858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>-1.668710</td>\n",
       "      <td>1.258125</td>\n",
       "      <td>-1.111517</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.114765</td>\n",
       "      <td>-1.209808</td>\n",
       "      <td>1.546161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>0.842932</td>\n",
       "      <td>-0.862210</td>\n",
       "      <td>-0.658845</td>\n",
       "      <td>2</td>\n",
       "      <td>1.188689</td>\n",
       "      <td>-0.174914</td>\n",
       "      <td>-1.376579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>1.371652</td>\n",
       "      <td>0.861149</td>\n",
       "      <td>-0.966656</td>\n",
       "      <td>0</td>\n",
       "      <td>0.929550</td>\n",
       "      <td>0.616987</td>\n",
       "      <td>-0.643962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>2.091386</td>\n",
       "      <td>-0.164420</td>\n",
       "      <td>-1.185916</td>\n",
       "      <td>0</td>\n",
       "      <td>1.918095</td>\n",
       "      <td>0.557593</td>\n",
       "      <td>-0.942563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>-0.460456</td>\n",
       "      <td>1.498658</td>\n",
       "      <td>1.349191</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.513903</td>\n",
       "      <td>1.046225</td>\n",
       "      <td>-0.666189</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1984 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             A         C         E  class         B         D         F\n",
       "0    -0.386248  1.536628  1.232589      1 -1.432057  1.039420  0.280469\n",
       "1    -2.686649  4.640702  0.823433      1 -4.036329  0.526320 -0.419013\n",
       "2     0.474124  1.576616 -1.256234      0  0.179770  0.157974 -0.162869\n",
       "3    -1.343790 -0.514008  1.520392      2 -1.299109 -0.152250  0.045123\n",
       "4    -2.187600  0.289041  1.318321      2 -2.089699 -0.494995 -0.661858\n",
       "...        ...       ...       ...    ...       ...       ...       ...\n",
       "1995 -1.668710  1.258125 -1.111517      0 -1.114765 -1.209808  1.546161\n",
       "1996  0.842932 -0.862210 -0.658845      2  1.188689 -0.174914 -1.376579\n",
       "1997  1.371652  0.861149 -0.966656      0  0.929550  0.616987 -0.643962\n",
       "1998  2.091386 -0.164420 -1.185916      0  1.918095  0.557593 -0.942563\n",
       "1999 -0.460456  1.498658  1.349191      1 -1.513903  1.046225 -0.666189\n",
       "\n",
       "[1984 rows x 7 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Reorder the columns in alphabetical order, but placing the class column as the last one; the cleaned dataframe must be named df; show its size and head (4pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'class'\n",
    "\n",
    "# Get the column names\n",
    "column_names = list(df.columns)\n",
    "\n",
    "# Remove the class column\n",
    "column_names.remove(target)\n",
    "\n",
    "# Sort the values\n",
    "column_names.sort()\n",
    "\n",
    "# Append class because we want it last\n",
    "column_names.append(target)\n",
    "\n",
    "# Reindex the dataframe                                                 #       QUI MODIFICA DAVVERO IL DATASET e riordina\n",
    "df = df.reindex(columns = column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "      <th>E</th>\n",
       "      <th>F</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.386248</td>\n",
       "      <td>-1.432057</td>\n",
       "      <td>1.536628</td>\n",
       "      <td>1.039420</td>\n",
       "      <td>1.232589</td>\n",
       "      <td>0.280469</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-2.686649</td>\n",
       "      <td>-4.036329</td>\n",
       "      <td>4.640702</td>\n",
       "      <td>0.526320</td>\n",
       "      <td>0.823433</td>\n",
       "      <td>-0.419013</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.474124</td>\n",
       "      <td>0.179770</td>\n",
       "      <td>1.576616</td>\n",
       "      <td>0.157974</td>\n",
       "      <td>-1.256234</td>\n",
       "      <td>-0.162869</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.343790</td>\n",
       "      <td>-1.299109</td>\n",
       "      <td>-0.514008</td>\n",
       "      <td>-0.152250</td>\n",
       "      <td>1.520392</td>\n",
       "      <td>0.045123</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-2.187600</td>\n",
       "      <td>-2.089699</td>\n",
       "      <td>0.289041</td>\n",
       "      <td>-0.494995</td>\n",
       "      <td>1.318321</td>\n",
       "      <td>-0.661858</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>-1.668710</td>\n",
       "      <td>-1.114765</td>\n",
       "      <td>1.258125</td>\n",
       "      <td>-1.209808</td>\n",
       "      <td>-1.111517</td>\n",
       "      <td>1.546161</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>0.842932</td>\n",
       "      <td>1.188689</td>\n",
       "      <td>-0.862210</td>\n",
       "      <td>-0.174914</td>\n",
       "      <td>-0.658845</td>\n",
       "      <td>-1.376579</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>1.371652</td>\n",
       "      <td>0.929550</td>\n",
       "      <td>0.861149</td>\n",
       "      <td>0.616987</td>\n",
       "      <td>-0.966656</td>\n",
       "      <td>-0.643962</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>2.091386</td>\n",
       "      <td>1.918095</td>\n",
       "      <td>-0.164420</td>\n",
       "      <td>0.557593</td>\n",
       "      <td>-1.185916</td>\n",
       "      <td>-0.942563</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>-0.460456</td>\n",
       "      <td>-1.513903</td>\n",
       "      <td>1.498658</td>\n",
       "      <td>1.046225</td>\n",
       "      <td>1.349191</td>\n",
       "      <td>-0.666189</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1984 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             A         B         C         D         E         F  class\n",
       "0    -0.386248 -1.432057  1.536628  1.039420  1.232589  0.280469      1\n",
       "1    -2.686649 -4.036329  4.640702  0.526320  0.823433 -0.419013      1\n",
       "2     0.474124  0.179770  1.576616  0.157974 -1.256234 -0.162869      0\n",
       "3    -1.343790 -1.299109 -0.514008 -0.152250  1.520392  0.045123      2\n",
       "4    -2.187600 -2.089699  0.289041 -0.494995  1.318321 -0.661858      2\n",
       "...        ...       ...       ...       ...       ...       ...    ...\n",
       "1995 -1.668710 -1.114765  1.258125 -1.209808 -1.111517  1.546161      0\n",
       "1996  0.842932  1.188689 -0.862210 -0.174914 -0.658845 -1.376579      2\n",
       "1997  1.371652  0.929550  0.861149  0.616987 -0.966656 -0.643962      0\n",
       "1998  2.091386  1.918095 -0.164420  0.557593 -1.185916 -0.942563      0\n",
       "1999 -0.460456 -1.513903  1.498658  1.046225  1.349191 -0.666189      1\n",
       "\n",
       "[1984 rows x 7 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataframe has size: 13888\n"
     ]
    }
   ],
   "source": [
    "# Show the size of the dataframe\n",
    "print(f\"The dataframe has size: {df.size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "      <th>E</th>\n",
       "      <th>F</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.386248</td>\n",
       "      <td>-1.432057</td>\n",
       "      <td>1.536628</td>\n",
       "      <td>1.039420</td>\n",
       "      <td>1.232589</td>\n",
       "      <td>0.280469</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-2.686649</td>\n",
       "      <td>-4.036329</td>\n",
       "      <td>4.640702</td>\n",
       "      <td>0.526320</td>\n",
       "      <td>0.823433</td>\n",
       "      <td>-0.419013</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.474124</td>\n",
       "      <td>0.179770</td>\n",
       "      <td>1.576616</td>\n",
       "      <td>0.157974</td>\n",
       "      <td>-1.256234</td>\n",
       "      <td>-0.162869</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.343790</td>\n",
       "      <td>-1.299109</td>\n",
       "      <td>-0.514008</td>\n",
       "      <td>-0.152250</td>\n",
       "      <td>1.520392</td>\n",
       "      <td>0.045123</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-2.187600</td>\n",
       "      <td>-2.089699</td>\n",
       "      <td>0.289041</td>\n",
       "      <td>-0.494995</td>\n",
       "      <td>1.318321</td>\n",
       "      <td>-0.661858</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          A         B         C         D         E         F  class\n",
       "0 -0.386248 -1.432057  1.536628  1.039420  1.232589  0.280469      1\n",
       "1 -2.686649 -4.036329  4.640702  0.526320  0.823433 -0.419013      1\n",
       "2  0.474124  0.179770  1.576616  0.157974 -1.256234 -0.162869      0\n",
       "3 -1.343790 -1.299109 -0.514008 -0.152250  1.520392  0.045123      2\n",
       "4 -2.187600 -2.089699  0.289041 -0.494995  1.318321 -0.661858      2"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show the head of the dataframe\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Find the best classification scheme using three classification methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use Decision Trees, Linear Perceptron and K-nearest Neighbors.\n",
    "\n",
    "Let's start by dividing our data into the feature matrix and the class labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(target, axis = 1)\n",
    "y = df[target]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now split the data into a training and a test set in order to see how well the classifiers perform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain, Xtest, ytrain, ytest = train_test_split(X, y, random_state = random_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the DecisionTree Classifier\n",
    "dt = DecisionTreeClassifier(random_state = random_state)\n",
    "\n",
    "# Fit it to the training data\n",
    "dt.fit(Xtrain, ytrain)\n",
    "\n",
    "# Try to predict training data\n",
    "dt_train_prediction = dt.predict(Xtrain)\n",
    "\n",
    "# Try to predict test data\n",
    "dt_test_prediction = dt.predict(Xtest)\n",
    "\n",
    "# Compute the accuracy score for the predictions\n",
    "dt_train_accuracy = accuracy_score(ytrain, dt_train_prediction) * 100\n",
    "dt_test_accuracy = accuracy_score(ytest, dt_test_prediction) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the Linear Perceptron\n",
    "lp = Perceptron(random_state = random_state)\n",
    "\n",
    "# Fit it to the training data\n",
    "lp.fit(Xtrain, ytrain)\n",
    "\n",
    "# Try to predict training data\n",
    "lp_train_prediction = lp.predict(Xtrain)\n",
    "\n",
    "# Try to predict test data\n",
    "lp_test_prediction = lp.predict(Xtest)\n",
    "\n",
    "# Compute the accuracy score for the predictions\n",
    "lp_train_accuracy = accuracy_score(ytrain, lp_train_prediction) * 100\n",
    "lp_test_accuracy = accuracy_score(ytest, lp_test_prediction) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the KNN Classifier\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "# Fit it to the training data\n",
    "knn.fit(Xtrain, ytrain)\n",
    "\n",
    "# Try to predict training data\n",
    "knn_train_prediction = knn.predict(Xtrain)\n",
    "\n",
    "# Try to predict test data\n",
    "knn_test_prediction = knn.predict(Xtest)\n",
    "\n",
    "# Compute the accuracy score for the predictions\n",
    "knn_train_accuracy = accuracy_score(ytrain, knn_train_prediction) * 100\n",
    "knn_test_accuracy = accuracy_score(ytest, knn_test_prediction) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how well the classifiers have performed using their default hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The decision tree had an accuracy of 100.00 on the training set and 81.85 on the test set\n",
      "The linear perceptron had an accuracy of 74.13 on the training set and 74.80 on the test set\n",
      "The knn classifier had an accuracy of 90.32 on the training set and 88.10 on the test set\n"
     ]
    }
   ],
   "source": [
    "print(f\"The decision tree had an accuracy of {dt_train_accuracy:.2f} on the training set and {dt_test_accuracy:.2f} on the test set\")\n",
    "print(f\"The linear perceptron had an accuracy of {lp_train_accuracy:.2f} on the training set and {lp_test_accuracy:.2f} on the test set\")\n",
    "print(f\"The knn classifier had an accuracy of {knn_train_accuracy:.2f} on the training set and {knn_test_accuracy:.2f} on the test set\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The linear perceptron behaved very oddly, having a higher accuracy on the test set, compared to the training one. The KNN classifier behaved the best overall, reaching a higher accuracy on the test set data. The decision tree shows signs of overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. For each classification method find the best parameter setting with cross validation on the training set (6pt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's prepare a few support structures that will help us in iterating over the classifiers for cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model labels to facilitate iterations\n",
    "model_lbls = ['dt', 'lp', 'knn']\n",
    "\n",
    "# We will evaluate classification via the precision metric\n",
    "score = 'precision'\n",
    "\n",
    "# Parameters for each classifier\n",
    "tuned_param_dt = [{'max_depth': list(range(1,dt.get_depth() + 1)), 'random_state': [random_state]}]\n",
    "tuned_param_lp = [{'early_stopping': [True], 'random_state': [random_state]}]\n",
    "tuned_param_knn =[{'n_neighbors': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]}]\n",
    "\n",
    "# set the models to be fitted specifying name, estimator and parameter structure\n",
    "models = {\n",
    "    'dt': {'name': 'Decision Tree       ',\n",
    "           'estimator': DecisionTreeClassifier(), \n",
    "           'param': tuned_param_dt,\n",
    "          },\n",
    "    'lp': {'name': 'Linear Perceptron   ',\n",
    "           'estimator': Perceptron(),\n",
    "           'param': tuned_param_lp,\n",
    "          },\n",
    "    'knn':{'name': 'K Nearest Neighbor ',\n",
    "           'estimator': KNeighborsClassifier(),\n",
    "           'param': tuned_param_knn\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To help us in this part, we will introduce this function we've used in one of the exercises during class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_results(model):\n",
    "    print(\"Best parameters set found on train set:\")\n",
    "    print()\n",
    "    # if best is linear there is no gamma parameter\n",
    "    print(model.best_params_)\n",
    "    print()\n",
    "    print(\"Grid scores on train set:\")\n",
    "    print()\n",
    "    means = model.cv_results_['mean_test_score']\n",
    "    stds = model.cv_results_['std_test_score']\n",
    "    params = model.cv_results_['params']\n",
    "    for mean, std, params_tuple in zip(means, stds, params):\n",
    "        print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "              % (mean, std * 2, params_tuple))\n",
    "    print()\n",
    "    print(\"Detailed classification report for the best parameter set:\")\n",
    "    print()\n",
    "    print(\"The model is trained on the full train set.\")\n",
    "    print(\"The scores are computed on the full test set.\")\n",
    "    print()\n",
    "    y_true, y_pred = ytest, model.predict(Xtest)\n",
    "    print(classification_report(y_true, y_pred))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now iterate on the models with GridSearchCV to find which one is the best performing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "Trying model Decision Tree       \n",
      "Best parameters set found on train set:\n",
      "\n",
      "{'max_depth': 7, 'random_state': 42}\n",
      "\n",
      "Grid scores on train set:\n",
      "\n",
      "0.432 (+/-0.022) for {'max_depth': 1, 'random_state': 42}\n",
      "0.814 (+/-0.040) for {'max_depth': 2, 'random_state': 42}\n",
      "0.814 (+/-0.043) for {'max_depth': 3, 'random_state': 42}\n",
      "0.826 (+/-0.039) for {'max_depth': 4, 'random_state': 42}\n",
      "0.815 (+/-0.050) for {'max_depth': 5, 'random_state': 42}\n",
      "0.827 (+/-0.045) for {'max_depth': 6, 'random_state': 42}\n",
      "0.833 (+/-0.056) for {'max_depth': 7, 'random_state': 42}\n",
      "0.828 (+/-0.045) for {'max_depth': 8, 'random_state': 42}\n",
      "0.825 (+/-0.033) for {'max_depth': 9, 'random_state': 42}\n",
      "0.830 (+/-0.041) for {'max_depth': 10, 'random_state': 42}\n",
      "0.822 (+/-0.045) for {'max_depth': 11, 'random_state': 42}\n",
      "0.827 (+/-0.054) for {'max_depth': 12, 'random_state': 42}\n",
      "0.823 (+/-0.053) for {'max_depth': 13, 'random_state': 42}\n",
      "0.811 (+/-0.042) for {'max_depth': 14, 'random_state': 42}\n",
      "0.816 (+/-0.039) for {'max_depth': 15, 'random_state': 42}\n",
      "0.813 (+/-0.041) for {'max_depth': 16, 'random_state': 42}\n",
      "0.810 (+/-0.040) for {'max_depth': 17, 'random_state': 42}\n",
      "0.810 (+/-0.040) for {'max_depth': 18, 'random_state': 42}\n",
      "\n",
      "Detailed classification report for the best parameter set:\n",
      "\n",
      "The model is trained on the full train set.\n",
      "The scores are computed on the full test set.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.79      0.79       152\n",
      "           1       0.85      0.77      0.81       173\n",
      "           2       0.84      0.91      0.87       171\n",
      "\n",
      "    accuracy                           0.82       496\n",
      "   macro avg       0.82      0.82      0.82       496\n",
      "weighted avg       0.83      0.82      0.82       496\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Trying model Linear Perceptron   \n",
      "Best parameters set found on train set:\n",
      "\n",
      "{'early_stopping': True, 'random_state': 42}\n",
      "\n",
      "Grid scores on train set:\n",
      "\n",
      "0.728 (+/-0.088) for {'early_stopping': True, 'random_state': 42}\n",
      "\n",
      "Detailed classification report for the best parameter set:\n",
      "\n",
      "The model is trained on the full train set.\n",
      "The scores are computed on the full test set.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.64      0.67       152\n",
      "           1       0.62      0.71      0.66       173\n",
      "           2       0.82      0.75      0.78       171\n",
      "\n",
      "    accuracy                           0.70       496\n",
      "   macro avg       0.71      0.70      0.70       496\n",
      "weighted avg       0.71      0.70      0.70       496\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Trying model K Nearest Neighbor \n",
      "Best parameters set found on train set:\n",
      "\n",
      "{'n_neighbors': 9}\n",
      "\n",
      "Grid scores on train set:\n",
      "\n",
      "0.819 (+/-0.043) for {'n_neighbors': 1}\n",
      "0.833 (+/-0.041) for {'n_neighbors': 2}\n",
      "0.850 (+/-0.043) for {'n_neighbors': 3}\n",
      "0.848 (+/-0.039) for {'n_neighbors': 4}\n",
      "0.848 (+/-0.025) for {'n_neighbors': 5}\n",
      "0.853 (+/-0.031) for {'n_neighbors': 6}\n",
      "0.849 (+/-0.038) for {'n_neighbors': 7}\n",
      "0.854 (+/-0.042) for {'n_neighbors': 8}\n",
      "0.856 (+/-0.039) for {'n_neighbors': 9}\n",
      "0.849 (+/-0.031) for {'n_neighbors': 10}\n",
      "\n",
      "Detailed classification report for the best parameter set:\n",
      "\n",
      "The model is trained on the full train set.\n",
      "The scores are computed on the full test set.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.80      0.83       152\n",
      "           1       0.87      0.84      0.85       173\n",
      "           2       0.86      0.94      0.90       171\n",
      "\n",
      "    accuracy                           0.86       496\n",
      "   macro avg       0.86      0.86      0.86       496\n",
      "weighted avg       0.86      0.86      0.86       496\n",
      "\n",
      "\n",
      "Summary of results for precision\n",
      "Estimator\n",
      "Decision Tree       \t - score: 83.31%\n",
      "Linear Perceptron   \t - score: 72.75%\n",
      "K Nearest Neighbor \t - score: 85.57%\n"
     ]
    }
   ],
   "source": [
    "results_short = {}\n",
    "\n",
    "for m in model_lbls:\n",
    "    print('-'*40)\n",
    "    print(\"Trying model {}\".format(models[m]['name']))\n",
    "    clf = GridSearchCV(models[m]['estimator'], models[m]['param'], cv=5,\n",
    "                        scoring='%s_macro' % score,  \n",
    "                        return_train_score = False,\n",
    "                        n_jobs = 2,\n",
    "                    )\n",
    "    \n",
    "    clf.fit(Xtrain, ytrain)\n",
    "    print_results(clf)\n",
    "    results_short[m] = clf.best_score_\n",
    "    \n",
    "print(\"Summary of results for {}\".format(score))\n",
    "print(\"Estimator\")\n",
    "for m in results_short.keys():\n",
    "    print(\"{}\\t - score: {:5.2f}%\".format(models[m]['name'], results_short[m]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the KNN classifier performed once again the best, followed by the decision tree and the linear perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. For each classification method compute the accuracy and the confusion matrix on the test set (4pt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's instantiate the classifiers with the best parameters we've found in the previous step:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = DecisionTreeClassifier(max_depth = 7, random_state = random_state)\n",
    "lp = Perceptron(early_stopping = True, random_state = random_state)\n",
    "knn = KNeighborsClassifier(n_neighbors = 9)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt.fit(Xtrain, ytrain)\n",
    "dt_pred = dt.predict(Xtest)\n",
    "dt_accuracy = accuracy_score(ytest, dt_pred) * 100\n",
    "dt_cm = confusion_matrix(ytest, dt_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of the DT classifier was 82.46%\n"
     ]
    }
   ],
   "source": [
    "print(f\"The accuracy of the DT classifier was {dt_accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The DT confusion matrix was:\n",
      "[[120  18  14]\n",
      " [ 23 134  16]\n",
      " [ 10   6 155]]\n"
     ]
    }
   ],
   "source": [
    "print(\"The DT confusion matrix was:\")\n",
    "print(dt_cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "lp.fit(Xtrain, ytrain)\n",
    "lp_pred = lp.predict(Xtest)\n",
    "lp_accuracy = accuracy_score(ytest, lp_pred) * 100\n",
    "lp_cm = confusion_matrix(ytest, lp_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of the LP classifier was 70.16%\n"
     ]
    }
   ],
   "source": [
    "print(f\"The accuracy of the LP classifier was {lp_accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The LP confusion matrix was:\n",
      "[[ 98  48   6]\n",
      " [ 28 122  23]\n",
      " [ 16  27 128]]\n"
     ]
    }
   ],
   "source": [
    "print(\"The LP confusion matrix was:\")\n",
    "print(lp_cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn.fit(Xtrain, ytrain)\n",
    "knn_pred = knn.predict(Xtest)\n",
    "knn_accuracy = accuracy_score(ytest, knn_pred) * 100\n",
    "knn_cm = confusion_matrix(ytest, knn_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of the KNN classifier was 86.29%\n"
     ]
    }
   ],
   "source": [
    "print(f\"The accuracy of the KNN classifier was {knn_accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The KNN confusion matrix was:\n",
      "[[122  18  12]\n",
      " [ 13 145  15]\n",
      " [  6   4 161]]\n"
     ]
    }
   ],
   "source": [
    "print(\"The KNN confusion matrix was:\")\n",
    "print(knn_cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DecisionTreeClassifier(max_depth=5, random_state=42):\n",
      "Accuracy: 83.46774193548387\n",
      "Confusion matrix: \n",
      "[[117  18  17]\n",
      " [ 17 140  16]\n",
      " [  6   8 157]]\n",
      "Classification report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.77      0.80       152\n",
      "           1       0.84      0.81      0.83       173\n",
      "           2       0.83      0.92      0.87       171\n",
      "\n",
      "    accuracy                           0.83       496\n",
      "   macro avg       0.84      0.83      0.83       496\n",
      "weighted avg       0.84      0.83      0.83       496\n",
      "\n",
      "\n",
      "Perceptron(early_stopping=True, random_state=42):\n",
      "Accuracy: 70.16129032258065\n",
      "Confusion matrix: \n",
      "[[ 98  48   6]\n",
      " [ 28 122  23]\n",
      " [ 16  27 128]]\n",
      "Classification report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.64      0.67       152\n",
      "           1       0.62      0.71      0.66       173\n",
      "           2       0.82      0.75      0.78       171\n",
      "\n",
      "    accuracy                           0.70       496\n",
      "   macro avg       0.71      0.70      0.70       496\n",
      "weighted avg       0.71      0.70      0.70       496\n",
      "\n",
      "\n",
      "KNeighborsClassifier():\n",
      "Accuracy: 88.10483870967742\n",
      "Confusion matrix: \n",
      "[[128  14  10]\n",
      " [ 13 149  11]\n",
      " [  7   4 160]]\n",
      "Classification report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.84      0.85       152\n",
      "           1       0.89      0.86      0.88       173\n",
      "           2       0.88      0.94      0.91       171\n",
      "\n",
      "    accuracy                           0.88       496\n",
      "   macro avg       0.88      0.88      0.88       496\n",
      "weighted avg       0.88      0.88      0.88       496\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Codice adattato da marco lorenzo per stampa ridotta e sistemata; (non salva precision e recall in strutture dati ma li stampa alla fine)\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "model_lbls = [\n",
    "              'dt', \n",
    "              'lp', \n",
    "             'knn'\n",
    "            ]\n",
    "\n",
    "# Set the parameters by cross-validation\n",
    "\n",
    "models = {\n",
    "    'dt': {'name': 'Decision Tree       ',\n",
    "           'estimator': DecisionTreeClassifier(max_depth = 5, random_state = random_state), \n",
    "          },\n",
    "    'lp': {'name': 'Linear Perceptron   ',\n",
    "           'estimator': Perceptron(early_stopping=True, random_state=random_state),\n",
    "          },\n",
    "    'knn':{'name': 'K Nearest Neighbor ',\n",
    "           'estimator': KNeighborsClassifier(n_neighbors=5),\n",
    "       }\n",
    "}\n",
    "\n",
    "dictModel_pred = {}\n",
    "dictModel_accuracy = {} \n",
    "dictModel_cm = {}\n",
    "\n",
    "\n",
    "def multipleClassifiers(model):\n",
    "    model.fit(Xtrain, ytrain)\n",
    "    model_pred = model.predict(Xtest)\n",
    "    model_accuracy = accuracy_score(ytest, model_pred) * 100\n",
    "    model_cm = confusion_matrix(ytest, model_pred)\n",
    "\n",
    "    dictModel_pred[model] = model_pred\n",
    "    dictModel_accuracy[model] = model_accuracy\n",
    "    dictModel_cm[model] = model_cm\n",
    "    \n",
    "    \n",
    "for model_lb in model_lbls:\n",
    "    model = models[model_lb][\"estimator\"]\n",
    "    multipleClassifiers(model)\n",
    "    print(\"\\n\"+str(model)+\":\")\n",
    "    print(\"Accuracy: \"+str(dictModel_accuracy[model]))\n",
    "    print(\"Confusion matrix: \")\n",
    "    print(dictModel_cm[model])\n",
    "    print(\"Classification report: \")\n",
    "    print(classification_report(ytest, dictModel_pred[model]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Produce a plot of the accuracies given by the methods attempted (3pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 3 artists>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAEICAYAAABGaK+TAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy89olMNAAAACXBIWXMAAAsTAAALEwEAmpwYAAAYRUlEQVR4nO3deZxlZX3n8c9XGmTfpINs2iioQUdb7VGJS4g4ahCFGXELIiojmhkNrhGXUXQyijFxC6MGQUDFBdEIEkUFRIgL2iwugEZkEwRpIyi4svzyx3kaLmXdqtvdVd39tJ/361WvPvv5nfOc+t5znntvdaoKSVJ/7rKmC5AkrRwDXJI6ZYBLUqcMcEnqlAEuSZ0ywCWpUwa41jlJHpnkh0luSrLvatrnYUk+srZsZ4btX5hkjzacJMckuT7JN5M8OskP5mvfmnsL1nQBmntJzgQeBNy9qn63hstZE94MHFFV717Thaxtqur+I6OPAv4bsGNV/apNu+/qr0oryzvwdUySRcCjgQKespr3vbbcENwTuHBNF9GBewKXj4T3SluL2v6PigG+7nkO8A3gWODA0RlJdkry6STLkvxHkiNG5r0gycVJbkxyUZKHtOmVZJeR5Y5N8ndteI8kVyV5dZJrgWOSbJXklLaP69vwjiPrb90e23/S5n+mTf9ekiePLLd+kp8lefB0B9nqvSTJz5OcnGT7Nv1HwL2Az7YulLtOs+72ST7Varwsyd+MzHtYkq8nuSHJNUmOSLLByPz7J/lS2+9Pk7x2ZNMbJPlQO4cXJlkyrpFm2c7ocp9Mcm2SXyQ5K8n9R+bt1drqxiRXJ3llm75NO+83tO2fneQubd7lSR6X5CDgKGD3dp7etLw9JzxPhyU5MclHkvwSeO64Y9X8McDXPc8Bjm8/T0iyLUCS9YBTgCuARcAOwMfbvKcBh7V1N2e4c/+PCfd3d2Brhru5gxmuqWPa+D2A3wBHjCz/YWBj4P7AnwDvbNM/BDx7ZLm9gGuq6vypO0zyWOCtwNOB7doxfRygqu4NXAk8uao2ndqF1ILss8C32znYE3hpkie0RW4FXgZsA+ze5v+vtu5mwGnAqcD2wC7A6SObf0qrY0vg5CnHPVrDbNsZ9XlgV4ZzdR5Duy53NPDCqtoMeABwRpv+CuAqYCGwLfBahiey21XV0cCLgK+38/TGFTxPAPsAJ7bjHa1Lq0tV+bOO/DD0ad4MbNPGvw+8rA3vDiwDFkyz3heAQ8Zss4BdRsaPBf6uDe8B/B7YcIaaFgPXt+HtgNuAraZZbnvgRmDzNn4i8Ldjtnk08Pcj45u2417Uxi8HHjdm3YcDV06Z9hrgmDHLvxT4lzb8LOD8McsdBpw2Mr4b8Jsxy862nY+Mmbdla48t2viVwAuXn7OR5d4MnDTabiPzbj83DHfN/zYybw/gqknOU6vzrDV9zf+x/3gHvm45EPhiVf2sjX+UO7pRdgKuqKpbpllvJ+BHK7nPZVX12+UjSTZO8s9JrmiP1mcBW7YngJ2An1fV9VM3UlU/Ab4KPDXJlsBfMv6ubnuGu+7l697E8MSwwwT13hPYvnUv3JDkBoY71OVPKvdp3Q/XtvrfwnA3DrOfp2tHhn8NbDimb3ii851kvSSHJ/lRq+XyNmt5PU9leFK5IslXkuzepr8duAT4YpJLkxw6276mMeN5an68EtvVHPKNh3VEko0YuhTWa/3RAHdlCM8HMfyy3SPJgmlC/MfAvcds+tcMXR7L3Z3h8Xy5qX/O8hUMn2R4eFVdm2QxcD6Qtp+tk2xZVTdMs6/jgP/JcF1+vaquHlPTTxgCBoAkmwB3A8YtP+rHwGVVteuY+e9r9T6rqm5M8lJgv5F1nznBPiapYZLt/BVDN8XjGMJ7C+B6hnNJVX0L2CfJ+sCLgROAnarqRoZ2eEWSBwBnJPlWVY3rphlX40znCf6w7bWaeQe+7tiXof92N4Zui8XAnwJnM/RtfxO4Bjg8ySZJNkzyyLbuUcArkzw0g12SLA/IC4C/aneDTwT+fJY6NmPo974hydbA7X2rVXUNQ5/uezO82bl+kseMrPsZ4CHAIQx94uN8DHheksXtTcq3AOdU1eWz1AbDebgxwxuvG7XjekCS/zpS/y+Bm5LcD/jrkXVPAbZL8tIkd02yWZKHT7DPqSbdzmbA7xieLjZuxwlAkg2S7J9ki6q6udV8W5u3d2vDAL9guC5uW8EaZztPWgsY4OuOAxn6J6+sqmuX/zC8kbY/w13bkxneMLuS4S76GQBV9Ung/zF0udzIEKRbt+0e0ta7oW3nM7PU8S5gI+BnDJ+GOXXK/AMY+qu/D1zH0MdMq+M3wKeAnYFPj9tBVZ0G/J+27DUMTw8T3RlX1a3A3gwvcJe1Oo9iuLsFeCXDne+NwAeAT4yseyPD56afzNBd8kPgLybZ75QaJt3Ohxi6iq4GLmI4n6MOAC5v3SsvYmgfGN70PA24Cfg68N6q+vIK1jjbedJaIFU+BWntkeQNwH2q6tmzLiz9kbMPXGuN1uVyEMOdpaRZ2IWitUKSFzC8cfb5qjprTdcj9cAuFEnqlHfgktSp1doHvs0229SiRYtW5y4lqXvnnnvuz6pq4dTpqzXAFy1axNKlS1fnLiWpe0mumG66XSiS1CkDXJI6ZYBLUqcMcEnqlAEuSZ0ywCWpUwa4JHXKAJekThngktQp/5ysJAAWHfqva7qEddblhz9pXrbrHbgkdcoAl6ROGeCS1CkDXJI6ZYBLUqcMcEnqlAEuSZ0ywCWpU918kccvGcyf+fqSgaT55R24JHXKAJekTk0U4EleluTCJN9L8rEkGybZOck5SS5J8okkG8x3sZKkO8wa4El2AP4GWFJVDwDWA54JvA14Z1XtAlwPHDSfhUqS7mzSLpQFwEZJFgAbA9cAjwVObPOPA/ad8+okSWPNGuBVdTXwD8CVDMH9C+Bc4IaquqUtdhWww3TrJzk4ydIkS5ctWzY3VUuSJupC2QrYB9gZ2B7YBHjipDuoqiOraklVLVm4cOFKFypJurNJulAeB1xWVcuq6mbg08AjgS1blwrAjsDV81SjJGkakwT4lcAjkmycJMCewEXAl4H92jIHAifNT4mSpOlM0gd+DsOblecB323rHAm8Gnh5kkuAuwFHz2OdkqQpJvoqfVW9EXjjlMmXAg+b84okSRPxm5iS1CkDXJI6ZYBLUqcMcEnqlAEuSZ0ywCWpUwa4JHXKAJekThngktQpA1ySOmWAS1KnDHBJ6pQBLkmdMsAlqVMGuCR1ygCXpE4Z4JLUqYn+Rx5pZSw69F/XdAnrrMsPf9KaLkFrAe/AJalTBrgkdcoAl6ROGeCS1CkDXJI6ZYBLUqcMcEnqlAEuSZ0ywCWpUwa4JHXKAJekThngktQpA1ySOmWAS1KnDHBJ6pQBLkmdMsAlqVMGuCR1ygCXpE4Z4JLUKQNckjo1UYAn2TLJiUm+n+TiJLsn2TrJl5L8sP271XwXK0m6w6R34O8GTq2q+wEPAi4GDgVOr6pdgdPbuCRpNZk1wJNsATwGOBqgqn5fVTcA+wDHtcWOA/adnxIlSdOZ5A58Z2AZcEyS85MclWQTYNuquqYtcy2w7XQrJzk4ydIkS5ctWzY3VUuSJgrwBcBDgPdV1YOBXzGlu6SqCqjpVq6qI6tqSVUtWbhw4arWK0lqJgnwq4CrquqcNn4iQ6D/NMl2AO3f6+anREnSdGYN8Kq6Fvhxkvu2SXsCFwEnAwe2aQcCJ81LhZKkaS2YcLmXAMcn2QC4FHgeQ/ifkOQg4Arg6fNToiRpOhMFeFVdACyZZtaec1qNJGlifhNTkjplgEtSpwxwSeqUAS5JnTLAJalTBrgkdcoAl6ROGeCS1CkDXJI6ZYBLUqcMcEnqlAEuSZ0ywCWpUwa4JHXKAJekThngktQpA1ySOmWAS1KnDHBJ6pQBLkmdMsAlqVMGuCR1ygCXpE4Z4JLUKQNckjplgEtSpwxwSeqUAS5JnTLAJalTBrgkdcoAl6ROGeCS1CkDXJI6ZYBLUqcMcEnqlAEuSZ0ywCWpUwa4JHXKAJekTk0c4EnWS3J+klPa+M5JzklySZJPJNlg/sqUJE21InfghwAXj4y/DXhnVe0CXA8cNJeFSZJmNlGAJ9kReBJwVBsP8FjgxLbIccC+81CfJGmMSe/A3wX8LXBbG78bcENV3dLGrwJ2mG7FJAcnWZpk6bJly1alVknSiFkDPMnewHVVde7K7KCqjqyqJVW1ZOHChSuzCUnSNBZMsMwjgack2QvYENgceDewZZIF7S58R+Dq+StTkjTVrHfgVfWaqtqxqhYBzwTOqKr9gS8D+7XFDgROmrcqJUl/YFU+B/5q4OVJLmHoEz96bkqSJE1iki6U21XVmcCZbfhS4GFzX5IkaRJ+E1OSOmWAS1KnDHBJ6pQBLkmdMsAlqVMGuCR1ygCXpE4Z4JLUKQNckjplgEtSpwxwSeqUAS5JnTLAJalTBrgkdcoAl6ROGeCS1CkDXJI6ZYBLUqcMcEnqlAEuSZ0ywCWpUwa4JHXKAJekThngktQpA1ySOmWAS1KnDHBJ6pQBLkmdMsAlqVMGuCR1ygCXpE4Z4JLUKQNckjplgEtSpwxwSeqUAS5JnTLAJalTBrgkdcoAl6ROzRrgSXZK8uUkFyW5MMkhbfrWSb6U5Ift363mv1xJ0nKT3IHfAryiqnYDHgH87yS7AYcCp1fVrsDpbVyStJrMGuBVdU1VndeGbwQuBnYA9gGOa4sdB+w7TzVKkqaxQn3gSRYBDwbOAbatqmvarGuBbcesc3CSpUmWLlu2bFVqlSSNmDjAk2wKfAp4aVX9cnReVRVQ061XVUdW1ZKqWrJw4cJVKlaSdIeJAjzJ+gzhfXxVfbpN/mmS7dr87YDr5qdESdJ0JvkUSoCjgYur6h0js04GDmzDBwInzX15kqRxFkywzCOBA4DvJrmgTXstcDhwQpKDgCuAp89LhZKkac0a4FX1b0DGzN5zbsuRJE3Kb2JKUqcMcEnqlAEuSZ0ywCWpUwa4JHXKAJekThngktQpA1ySOmWAS1KnDHBJ6pQBLkmdMsAlqVMGuCR1ygCXpE4Z4JLUKQNckjplgEtSpwxwSeqUAS5JnTLAJalTBrgkdcoAl6ROGeCS1CkDXJI6ZYBLUqcMcEnqlAEuSZ0ywCWpUwa4JHXKAJekThngktQpA1ySOmWAS1KnDHBJ6pQBLkmdMsAlqVMGuCR1ygCXpE4Z4JLUqVUK8CRPTPKDJJckOXSuipIkzW6lAzzJesD/B/4S2A14VpLd5qowSdLMVuUO/GHAJVV1aVX9Hvg4sM/clCVJms2CVVh3B+DHI+NXAQ+fulCSg4GD2+hNSX6wCvvsyTbAz9Z0EZPI29Z0BWuFbtoLbLOmmzabg/a653QTVyXAJ1JVRwJHzvd+1jZJllbVkjVdhyZje/XHNlu1LpSrgZ1Gxnds0yRJq8GqBPi3gF2T7JxkA+CZwMlzU5YkaTYr3YVSVbckeTHwBWA94INVdeGcVda/P7puo87ZXv35o2+zVNWarkGStBL8JqYkdcoAl6ROrZMBnuTWJBckuTDJt5O8IslKHWuSNyd53AzzX5TkOStfLST5L63eC5L8PMllbfi0VdnumpbkpmmmrfL5Wok6zmx/8uHbSb6a5L6rc/+thsVJ9lrd+53OaLsk2SvJvye555RlLk/yqZHx/ZIcuxrLHK3ltTPMW+E6kyxJ8p5ZllmU5Htj5p2ZZK34+OK8fw58DflNVS0GSPInwEeBzYE3ruiGquoNs8x//8oUOGUb3wUWA7SL75SqOnF0mSQLquqWVd3XmjYX52smScLw3s5tU2btX1VL2xfL3g48ZRW2tTIWA0uAz02znzXStkn2BN4DPKGqrphmkYcm2a2qLprDfa7Msb4WeMsM81eozqpaCixdwRrmxFy39Tp5Bz6qqq5j+CboizNYL8nbk3wryXeSvHD5skleneS77U7t8Dbt2CT7teHDk1zU1vuHNu2wJK9sw4uTfKPN/5ckW7XpZyZ5W5JvtrudR09Se1vvXUmWAockeWiSryQ5N8kXkmzXlrt3klPb9LOT3G8OT+GcmnK+pj0v49ooyaZJTk9yXmunfdr0Re0O+0PA97jz9xOmOgvYpa33qpF9vGnctsZcF9Oe83a9vD/J0nZMe2f4mO2bgWdkeLJ6RjsPH07yVeDDbb9ntFpOT3KPke29J8nXkly6/Fqcg3Z4DPABYO+q+tGYxf4ReN00626S5IOt3c6f0g5nt/Y5L8mftel7tOknAxfN0L7bJTmrnaPvJXl0O98btWnHz1GdeyQ5pQ0vTPKlDE/rRyW5Isk2bRPrJflAm/fFJBuNbP6AkTof1ra1dZLPtGP6RpIHtulT2/r+raYL2rK7jm2o2VTVOvcD3DTNtBuAbRnC/PVt2l0ZXol3ZvijXF8DNm7ztm7/HgvsB9wN+AF3fHJny/bvYcAr2/B3gD9vw28G3tWGzwT+sQ3vBZw2Q+3HAvuNrPfeNrx+q29hG38Gw0c3AU4Hdm3DDwfOWNNtMEM7jJ6vac/LDG20ANi8Td8GuAQIsAi4DXjEmDrOBJa04VcBnwAez/AxtDDcyJwCPGbqtma4LqY95639Tm3b3JXhT0xsCDwXOGLKeTgX2KiNfxY4sA0/H/jMyPY+2ba3G8PfH1rVdrkZ+DnwwBmWuZzh9+Vihhe8/YBj27y3AM9e/nsA/DuwCbAxsGGbviuwtA3vAfwK2HmW9n0F8Lo2fT1gs3HX0SrWuQfDUy7AEcBr2vATgWK4thYBtwCL27wTRrZ1JvCBNvwY4Htt+J+AN7bhxwIXjGnrf2J4IgTYYPn0lflZV7tQZvJ44IEjdzJbMFxsjwOOqapfA1TVz6es9wvgt8DR7dX7lNGZSbZgCPWvtEnHMfziLffp9u+5DBfHpD7R/r0v8ADgS0lguMCvSbIp8GfAJ9t0GH4pejHdeRnXRlcBb2l3j7cx/D2ebdsyV1TVN2bYz/FJfsPwC/8S4JC2n/Pb/E3bPq6csq0/uC4mOOcn1NDt8sMklwLjnohOrqrftOHdgf/Rhj8M/P3Icp9p27soybasupsZXpQOYjgP49zK0N30GuDzI9MfDzwl7UmK4QXqHsBPgCOSLG7r3mdknW9W1WUj60/Xvt8CPphkfYZjvmDC41nROkc9CvjvAFV1apLrR+ZdNlLD1N/bj7V1zkqyeZIt27ae2qafkeRuSTZvy4+29deB1yXZEfh0Vf1wwuP8A38UAZ7kXgyNfB3DHddLquoLU5Z5wkzbqOGLSw8D9mR4lX8xw6vspH7X/r2VFTvvv1peInBhVe0+OrNdIDdU6/Pv0HTnZVwbPRdYCDy0qm5OcjnDLyXccZ7G2b+Gvs/l2wrw1qr65yn7WDTBtu7CzOd86pcrxn3ZYrb9LPe7keGMXWpytwFPB07P8Abh2xgCCoagGX3f58MMwTj6hl6Ap1bVnf4wXZLDgJ8CD2I4R78dmT16rNO2b9vGY4AnAccmeUdVfWjCY1qROid9ERw977cCo10ok7bxcrcff1V9NMk5DMf5uSQvrKozJqzpTtb5PvAkC4H3Mzy+FsM3R/+6vcqT5D5JNgG+BDwvycZt+tZTtrMpsEVVfQ54GcNFeruq+gVwfe7o3z4A+Apz5wfAwiS7t3rWT3L/qvolcFmSp7XpSfKgmTbUgXFttAVwXQvvv2DMX2hbgX08v7UrSXbI8Ib3VH9wXUxwzp+W5C5J7g3ci6HtbgQ2m6GerzH8OQqA/YGzV+HYZtWeKJ7U9vXcqlrcft4wZbmbgXcyXPPLfQF4SXsRJMmD2/QtgGva08IBDE+J05m2fTN8EuanVfUB4CjgIW35m5cvO8PxrEido77K8GJGkscDW820nxHPaOs8CvhF+/0/m+F8kmQP4GftWrmTdkN5aVW9BzgJeOCE+/wD6+od+EZJLmDoN76F4dX5HW3eUQyPQue1hl0G7NsenxYDS5P8nuHTAqMfX9oMOCnJhgyv7C+fZr8HAu9vv+yXAs+bqwOqqt+3R873tO6aBcC7gAsZLpr3JXl9O+aPA9+eq32vgo2TXDUy/o6xS97ZtG0EHA98Nsl3GfpNv7+yhVXVF5P8KfD19vt9E/Bshjut0eXGXRcznfMrgW8yfPLpRVX12yRfBg5t1+VbpynpJcAxSV7VjnfOrp1xWnfQE4GzkiyrqnF/y+ho4PUj4/+X4dr7ToaP514G7A28F/hUho+Jnsr4J4xx7bsH8KokNzO0x/KPmx7Z9nVeVe0/wyFNWueoNwEfS3IAQ9fGtQwvtpvOsB+A3yY5n6Htn9+mHcbQBfQd4NcMeTCdpzO8CXpz299Mn7CZkV+ll+ZQxnwMVGunJHcFbm1dpLsD7+upO3JdvQOXpEncAzih3aH/HnjBGq5nhXgHLkmdWuffxJSkdZUBLkmdMsAlqVMGuCR1ygCXpE79J6jtNIbXvUw2AAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "classifier_list = ['Decision Tree', 'Linear Perceptron', 'K-Nearest Neighbors']\n",
    "acc_list = [dt_accuracy, lp_accuracy, knn_accuracy]\n",
    "plt.title('Accuracy of each classifier')\n",
    "plt.bar(classifier_list, acc_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0 (tags/v3.10.0:b494f59, Oct  4 2021, 19:00:18) [MSC v.1929 64 bit (AMD64)]"
  },
  "orig_nbformat": 2,
  "vscode": {
   "interpreter": {
    "hash": "b1708fff10be9fb692d7fda4b87bbb8793f7d6a3cb1c2c80debaadfcc2f4e575"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
