{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c53e0a98-41bd-48b5-9641-1cddd679c3e9",
   "metadata": {},
   "source": [
    "# Luca Corsetti 0001131095"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d20666cf-40cd-414a-81a1-5404e9e43936",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "random_state=777\n",
    "\n",
    "np.random.seed(random_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e9a95fd-e4f7-4607-8ec1-61aa57eb45d7",
   "metadata": {},
   "source": [
    "Consider the file provided with the assignment and execute the analysis described below according to the best practices of Machine Learning. You are\n",
    "allowed to use only the computers of the lab, you are not allowed to use any other device, email or any other messaging tool. You can use only the websites\n",
    "accessible through the computers of the lab, as listed in the following page.\n",
    "Cooperative work will be heavily sanctioned\n",
    "\n",
    "The notebook must operate as follows:\n",
    "1. Load the file data.csv, explore the data showing size and do some data\n",
    "exploration . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1pt\n",
    "2. Deal with null values, imputing the mean for numeric features and the\n",
    "string “unknown” for categorical features . . . . . . . . . . . . . . . . . . . . . . . . . 2pt\n",
    "3. train, optimize and test two classifier models of your choice, the\n",
    "optimization must be done with cross validation, optimize the f1-\n",
    "score_macro . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 4pt\n",
    "4. show the result for both models, including the optimal hyperparameter\n",
    "values . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1pt\n",
    "5. repeat the experiment using the best model found in the previous steps\n",
    "and doing feature selection . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 4pt\n",
    "6. show the results with the best hyperparameter values . . . . . . . . . . . . 1pt\n",
    "7. comment the results of the two experiments . . . . . . . . . . . . . . . . . . . . 3pt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8789654d-4bf2-4524-a6d4-4a93f4536ca2",
   "metadata": {},
   "source": [
    "### 1. Load the file data.csv, explore the data showing size and do some data exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d7b80c10-b03a-443f-87fc-28833d1382e4",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './data.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m./data.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex_col\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m df\u001b[38;5;241m.\u001b[39mhead()\n",
      "File \u001b[0;32m~/src/unibo/unibo-MLDM/.venv/lib/python3.13/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/src/unibo/unibo-MLDM/.venv/lib/python3.13/site-packages/pandas/io/parsers/readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/src/unibo/unibo-MLDM/.venv/lib/python3.13/site-packages/pandas/io/parsers/readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/src/unibo/unibo-MLDM/.venv/lib/python3.13/site-packages/pandas/io/parsers/readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/src/unibo/unibo-MLDM/.venv/lib/python3.13/site-packages/pandas/io/common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './data.csv'"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('./data.csv', index_col=0)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d22325b-2d0b-4cc4-a537-eacd6d053cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"the dataset has {df.shape[0]} rows and {df.shape[1]} columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c20361f-d58c-4c58-95d5-1ffa2cb00627",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "208279d0-1e71-4124-9589-0c0edd99f291",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d28d870c-37ef-4c0f-af13-81add3b5581c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"there are {df['F00'].isna().sum()} rows with F00 having NaN values out of {df.shape[0]} records in the dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d62697ee-46f0-4b9b-9a61-58aceb5c9872",
   "metadata": {},
   "source": [
    "- the data is composed for the majority of numeric values\n",
    "- the column 'class' denotes the column that will be used to classify the data.\n",
    "- the column 'F13' seems to represent some sort of category\n",
    "- the column 'F00' seems to have lots of NaN values, in fact 950 out of 1000 rows in the dataset have missing value in this column. we will likely need to work on the column, either by purging it entirely or by filling it with some values\n",
    "\n",
    "the dataset has a lot of features, we may therefore encounter not-so-great performances on our trained classifiers. maybe we will need to do some feature selection to improve our models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3383f013-71d5-45a6-9ac9-cde9c6d1bdf2",
   "metadata": {},
   "source": [
    "### 2. Deal with null values, imputing the mean for numeric features and the string “unknown” for categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ef66253-6e51-4dc4-b966-dd3762abbdaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a2ffa2e-5a42-441c-a579-82d29e2286f7",
   "metadata": {},
   "source": [
    "only the column \"F00\" seems to have NaN values, we proceed by setting it with the mean of the values present for the same feature column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35e29ece-a3b8-4746-b67c-4aaacda5950a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = df['F00'].mean()\n",
    "\n",
    "df['F00'] = df['F00'].replace(np.nan, mean)\n",
    "\n",
    "# we could also do this iteratively for each column\n",
    "\n",
    "# for c in df.columns:\n",
    "#    mean = df[c].mean()\n",
    "\n",
    "#    df[c] = df[c].replace(np.nan, mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5d1b206-f10e-4c13-b492-54105af6a945",
   "metadata": {},
   "source": [
    "categorical features do not seem to be having missing values, but in order for the classifiers to work, we need to encode them in a numeric format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35a122e4-2ccd-47cd-9d5a-62dd13516e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = OrdinalEncoder(dtype=int)\n",
    "\n",
    "df['F13'] = pd.DataFrame(enc.fit_transform(pd.DataFrame(df['F13'], columns=['F13'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0bfe70e-f748-40d7-adec-50e3b5b6bdbf",
   "metadata": {},
   "source": [
    "### 3. train, optimize and test two classifier models of your choice, the optimization must be done with cross validation, optimize the f1-score_macro"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daffe5a2-1b6a-40bb-ad3b-d013090b842b",
   "metadata": {},
   "source": [
    "firstly, we need to split the data into train & test before training the classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42638661-f760-4cfc-b439-1f098566d1f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['class']\n",
    "X = df.drop(columns=['class'])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=random_state)\n",
    "\n",
    "print(f\"the training set has {X_train.shape[0]} samples\")\n",
    "print(f\"the training set has {X_test.shape[0]} samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f080d3ba-ff08-4396-973d-f0fdfc0d0081",
   "metadata": {},
   "source": [
    "for this task we will use the *DecisionTreeClassifier* and the *KNeighborsClassifier* classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a6a11e9-2525-40e0-a6c5-7204a1dc9c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_model = DecisionTreeClassifier(random_state=random_state)\n",
    "\n",
    "tree_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred_tree = tree_model.predict(X_test)\n",
    "tree_accuracy_score = accuracy_score(y_test, y_pred_tree)\n",
    "\n",
    "print(f\"decision tree trained, max_depth reached={tree_model.tree_.max_depth}, with an accuracy of {tree_accuracy_score*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fe4fe92-3625-444c-9a32-3426656883f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "kn_model = KNeighborsClassifier()\n",
    "\n",
    "kn_model.fit(X_train, y_train)\n",
    "y_pred_kn = kn_model.predict(X_test)\n",
    "kn_accuracy_score = accuracy_score(y_test, y_pred_kn)\n",
    "\n",
    "print(f\"decision tree trained, with an accuracy of {kn_accuracy_score*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "075b05af-930c-4b03-81f7-3cf0f5d10429",
   "metadata": {},
   "source": [
    "let's try to optimize them using cross validation over the \"f1-score_marco\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6e7d113-a8ac-4a89-a663-84f43f2a6824",
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring = 'f1_macro'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc24f515-4fc4-419e-b13a-caee3b69d53d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_params = [{ \"max_depth\": range(1, tree_model.tree_.max_depth + 1), \"criterion\": [\"gini\", \"entropy\"] }]\n",
    "\n",
    "tree_cv = GridSearchCV(\n",
    "    estimator=DecisionTreeClassifier(random_state=random_state),\n",
    "    param_grid=tree_params,\n",
    "    cv=5,\n",
    "    n_jobs=2\n",
    ")\n",
    "\n",
    "tree_cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "924563fa-7d27-44c7-b17d-f73b3dc15e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "kn_params = [{ \"n_neighbors\": range(1, 15), \"weights\": [\"uniform\", \"distance\"] }]\n",
    "\n",
    "kn_cv = GridSearchCV(\n",
    "    estimator=KNeighborsClassifier(),\n",
    "    param_grid=kn_params,\n",
    "    cv=5,\n",
    "    n_jobs=2\n",
    ")\n",
    "\n",
    "kn_cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41e705d2-f078-4322-9901-4e4bb600be94",
   "metadata": {},
   "source": [
    "### 4. show the result for both models, including the optimal hyperparameter values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aab8062-5654-45e8-98fd-65e74ef6b3fd",
   "metadata": {},
   "source": [
    "let's compute some metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b937664e-5228-481b-bbe9-8168dcbf3e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_tree_tuned_pred = tree_cv.best_estimator_.predict(X_test)\n",
    "\n",
    "tree_tuned_cr = classification_report(y_test, y_tree_tuned_pred, zero_division=np.nan, output_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c3ca275-912b-4926-a2cc-c748f0a5a1d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_kn_tuned_pred = kn_cv.best_estimator_.predict(X_test)\n",
    "\n",
    "kn_tuned_cr = classification_report(y_test, y_kn_tuned_pred, zero_division=np.nan, output_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7443e1b-ccb4-49bb-8512-c35741da8cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame([\n",
    "              ['dt', tree_cv.best_params_, tree_tuned_cr['accuracy'], tree_tuned_cr['0']['recall'], tree_tuned_cr['0']['f1-score']],\n",
    "              ['kn', kn_cv.best_params_, kn_tuned_cr['accuracy'], kn_tuned_cr['0']['recall'], kn_tuned_cr['0']['f1-score']]\n",
    "          ], columns=['model', 'best_params', 'accuracy', 'recall', 'f1-score'])\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6adfeaf7-a855-428c-b7d6-ab2d1eebb0fd",
   "metadata": {},
   "source": [
    "KNearestNeighbors seems to be the best model, scoring 82% of accuracy, better recall and better f1-score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3f73a97-3cb0-4ff4-96b8-e5a13f783814",
   "metadata": {},
   "source": [
    "### 5. repeat the experiment using the best model found in the previous steps and doing feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c3672c0-f287-499e-b160-951e6ac7faae",
   "metadata": {},
   "source": [
    "let's try to see what features to remove using correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f3e696-d089-4cf5-b477-3bc32c8ad4d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce722744-0fb8-4651-aa9d-102a58559128",
   "metadata": {},
   "source": [
    "we will remove:\n",
    "- \"F06\", \"F09\" because they have perfect correlation with \"F03\". also, supporting this choice, \"F06\" and \"F09\" seems to be highly correlated (> .82) with F07\n",
    "- \"F14\" because it has high correlation (> .92) with \"F02\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c0b0541-cd54-479a-935e-c1014e0b0a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: class target can remain the same, hence 'y' is not altered\n",
    "X_feat = df.drop(columns=['F06', 'F09', 'F14'])\n",
    "\n",
    "X_feat_train, X_feat_test, _, _ = train_test_split(X_feat, y, random_state=random_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "705fb715-0531-43bc-a7ad-07131164d545",
   "metadata": {},
   "source": [
    "let's now repeat the training and see the results on the feature-selected dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d6a2c4-89cc-4c7b-93f3-dac45193ee1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "kn_feat_cv = GridSearchCV(\n",
    "    estimator=KNeighborsClassifier(),\n",
    "    param_grid=kn_params,\n",
    "    cv=5,\n",
    "    n_jobs=2\n",
    ")\n",
    "\n",
    "kn_feat_cv.fit(X_feat_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7cc4b2f-5dd7-40bf-a10d-ac3389b158a2",
   "metadata": {},
   "source": [
    "### 6. show the results with the best hyperparameter values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa944e6e-d20a-41b8-aae3-3548f7690360",
   "metadata": {},
   "source": [
    "let's see the results of the trained models with the feature selected dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bff28d9-3c06-4b12-8b5e-6b97060144e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_kn_feat_pred = kn_feat_cv.best_estimator_.predict(X_feat_test)\n",
    "\n",
    "kn_feat_cr = classification_report(y_test, y_kn_feat_pred, zero_division=np.nan, output_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34b18d47-a8e8-4fdb-a3da-4e22bc91d568",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_feat = pd.DataFrame([\n",
    "              ['kn_feat', kn_feat_cv.best_params_, kn_feat_cr['accuracy'], kn_feat_cr['0']['recall'], kn_feat_cr['0']['f1-score']]\n",
    "          ], columns=['model', 'best_params', 'accuracy', 'recall', 'f1-score'])\n",
    "\n",
    "results_feat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50e64fff-6d75-4c12-b4ef-0c72244e419b",
   "metadata": {},
   "source": [
    "### 7. comment the results of the two experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c31765e5-a8ba-486b-91a1-9617ba47a4bb",
   "metadata": {},
   "source": [
    "by performing feature selection over the dataset and using the best previously found estimator (KNearestNeighborsClassifier), we were able to increment the accuracy of the model, scoring a 87.6% of accuracy (previouslu we achieved 82%)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
