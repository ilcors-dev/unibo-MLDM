{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eTqxI1TauqIN"
   },
   "source": [
    "# CLASSIFICATION Snippets e Scheletro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ScsmTqnFuqIQ"
   },
   "source": [
    "## 1. Elaborazione dei Dati"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rK0IJZepuqIR"
   },
   "source": [
    "### Import e preparazione delle strutture dati"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i9XUFgieuqIS"
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Variables\n",
    "file_name= 'File_Name.csv'\n",
    "file_name_2 = 'File_Name_2.csv'\n",
    "separator = 'Separator'\n",
    "random_state = 42\n",
    "target = 'Class_Target'\n",
    "\n",
    "# Directives\n",
    "%matplotlib inline\n",
    "np.random.seed(random_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q0UwqTEDuqIU"
   },
   "source": [
    "### Caricamento delle strutture dati"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p0dY6tAjuqIU"
   },
   "outputs": [],
   "source": [
    "# Load file (Prima riga ci sono le label e la prima colonna ha gli indici)\n",
    "df = pd.read_csv(file_name, delimiter = separator, header = 0, index_col = 0)\n",
    "\n",
    "# Load file (DataSet senza label e indici)\n",
    "df = pd.read_csv(file_name, delimiter = separator, header=None, index_col=None)\n",
    "\n",
    "# Load file (DataSet con names)\n",
    "df = pd.read_csv(file_name, delimiter = separator, header=None, index_col=None, names=['colonna1', 'colonna2'])\n",
    "\n",
    "# Load file (with index but without column name)\n",
    "col_names=['Index', 'Sex', 'Length', 'Diameter','Height','Whole weight','Shucked weight','Viscera weight','Shell weight','Rings']\n",
    "df=pd.read_csv(file_name, sep=separator, header=None, names=col_names, index_col=['Index'])\n",
    "\n",
    "# Load data from a .txt file\n",
    "text = np.loadtxt(file_name, delimiter = separator)\n",
    "df = pd.DataFrame(text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J3WoKV_WRBR5"
   },
   "source": [
    "Assegnare nomi alle colonne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "avDGy2oZRFmC"
   },
   "outputs": [],
   "source": [
    "# assegnare dei nomi alle colonne se in dataset originale non ha nomi alle colonne\n",
    "columns =[]\n",
    "for i in range(df.shape[1]):\n",
    "    columns.append(str(i)) # ['0','1' .... ]\n",
    "\n",
    "df.columns = columns\n",
    "\n",
    "# assegnare dei nomi alle colonne se in dataset originale non ha nomi alle colonne\n",
    "columns =[]\n",
    "for i in range(df.shape[1]):\n",
    "    columns.append(str(i)) # ['0','1' .... ]\n",
    "\n",
    "# last element\n",
    "columns[-1] = 'Class_target'\n",
    "df.columns = columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L8f5AL_5uqIV"
   },
   "source": [
    "### Mostra dei dati (SIZE, DESCRIBE, BOXPLOT, PAIRPLOT, CORRELATION MATRIX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v-L6gFbgREjB"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EjVaG9gyuqIV"
   },
   "outputs": [],
   "source": [
    "# Show the DataFrame (All)\n",
    "df\n",
    "\n",
    "# Show Structure\n",
    "df.describe()\n",
    "\n",
    "# Show the head of the dataframe\n",
    "df.head()\n",
    "\n",
    "# For each column show the frequencies of each distinct value\n",
    "np.unique(df, return_counts = True)\n",
    "\n",
    "# Show the number of rows and columns\n",
    "print(f\"There are {df.shape[0]} rows and {df.shape[1]} columns in this dataset\")\n",
    "\n",
    "# Show Shape\n",
    "print (\"The shape is: {}\".format(df.shape))\n",
    "\n",
    "# Show the size of the dataframe\n",
    "print(f\"The dataframe has size: {df.size}\")\n",
    "\n",
    "# Pairplot (relazioni fra attributi rispetto al target)\n",
    "# NON TIENE VALORI STRINGHE (NO ERRORI)\n",
    "sns.pairplot(df, hue = target)\n",
    "\n",
    "# Boxplot (trovare Outliers)\n",
    "# NON TIENE VALORI STRINGHE (DA ERRORI, DA TOGLIERE)\n",
    "plt.figure(figsize=(15,15))\n",
    "pos = 1\n",
    "for i in df.columns:\n",
    "        if(type(df[i][0]) != str):\n",
    "                plt.subplot(4, 3, pos)\n",
    "                sns.boxplot(df[i])\n",
    "                pos += 1\n",
    "\n",
    "# Boxplot\n",
    "# Drop column stringa\n",
    "df_for_boxplot = df.drop(['Column_containing_string_type'], axis=1)\n",
    "plt.figure(figsize=(15,15))\n",
    "pos = 1\n",
    "for i in df_for_boxplot.columns:\n",
    "    plt.subplot(3, 4, pos)\n",
    "    sns.boxplot(data=df[i])\n",
    "    pos += 1\n",
    "\n",
    "# Correlation Matrix\n",
    "correlation_matrix = df.corr()\n",
    "sns.heatmap(correlation_matrix, cmap=\"YlGnBu\", annot=True)\n",
    "\n",
    "#Check the number of rows with missing values\n",
    "rows_missingvalues = df.isna().any(axis=1).sum()\n",
    "print(\"Rows with missing values: {}\".format(rows_missingvalues))\n",
    "\n",
    "# Histogram of numeric data\n",
    "pd.DataFrame.hist(df, figsize=[15,15]);\n",
    "\n",
    "# Histogram of the column target (even if a string)\n",
    "df['target'].hist()\n",
    "\n",
    "# Scatter Plot (X column 0 and Y column 1 of df)\n",
    "sns.scatterplot(x=focus[0], y=focus[1], data=df, hue=\"target\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "49RQ4okHuqIW"
   },
   "source": [
    "### Modifica del DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kwW_vi2fuqIX"
   },
   "outputs": [],
   "source": [
    "# Merge the two dataframes with the 'outer' how, as to perform a SQL-like full outer join\n",
    "# on the two indexes, adding suffixes as requested (default option)\n",
    "# (Entrambi hanno Indici e prima riga Label da differenziare Target)\n",
    "df = first_df.merge(second_df, how = 'outer', left_index = True, right_index = True, suffixes = ('_x', '_y'))\n",
    "\n",
    "# Drop those rows from the dataframe\n",
    "df = df.drop(index = indexes_to_delete, axis = 0)\n",
    "\n",
    "# Drop specific column\n",
    "df = df.drop(columns = 'Column_Name', axis = 1)\n",
    "\n",
    "# Drop more than 1 column\n",
    "df = df.drop(columns = ['Column_Name1', 'Column_Name2'], axis = 1)\n",
    "\n",
    "# Rename specific column\n",
    "df = df.rename(columns = {'Old_Name1':'New_Name1', 'Old_Name2':'New_name2'})\n",
    "\n",
    "# Get the column names\n",
    "column_names = list(df.columns)\n",
    "\n",
    "# Reindex the dataframe\n",
    "df = df.reindex(columns = column_names)\n",
    "\n",
    "# Eliminate the rows containing null values\n",
    "df = df.dropna()\n",
    "\n",
    "# Delete row where value in column 1 is different from column 2\n",
    "df = df.drop(df[df['class_x'] !=  df['class_y']].index)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mYVNZjZXuqIY"
   },
   "source": [
    "Commenti sui valori"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WFDw7mBouqIY"
   },
   "outputs": [],
   "source": [
    "# We can see that there are some distributions that are very similar and higly correlated (such as Length/Diameter\n",
    "# or the different weights) and there is also a significant presence of outliers.\n",
    "# All the weight attributes are skewed on the left and have a long tail.\n",
    "# Also, our data contains some missing values.\n",
    "# All this things can compromise our analysis so it's time to pre-process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E_A1qMf0uqIY"
   },
   "source": [
    "### Trasformazione dei dati per Grafici o altro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8BEKrMuruqIZ"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "column_target = 'target'\n",
    "\n",
    "# Set the transformer data type (if required)\n",
    "transf_dtype = np.int32\n",
    "\n",
    "# machineLearning-03c-prepr-dissim.pdf 25/71\n",
    "# Specific columns dataframe to one hot encoding , add new columns drop old column\n",
    "# OneHotEncoder (da Nominal a Numerical)\n",
    "# from 1 column to n column of 0/1\n",
    "encoder = OneHotEncoder(dtype = transf_dtype)\n",
    "transformed = encoder.fit_transform(df[[column_target]])\n",
    "df[encoder.categories_[0]] = transformed.toarray()\n",
    "df = df.drop(column_target, axis = 1)\n",
    "\n",
    "# Specific column dataframe to one hot encoding , inplace\n",
    "# OrdinalEncoder (da Ordinal a Numerical)\n",
    "encoder = OrdinalEncoder(dtype = transf_dtype)\n",
    "df[column_target] = encoder.fit_transform(df[[column_target]])\n",
    "\n",
    "# All dataframe to one hot encoding\n",
    "# from Nominal to Numerical\n",
    "transf_dtype = np.int32\n",
    "encoder = OneHotEncoder(handle_unknown = 'ignore', sparse = False, dtype = transf_dtype)\n",
    "# Fit and transform the data\n",
    "X_e = encoder.fit_transform(df)\n",
    "X_ohe = pd.DataFrame(X_e)\n",
    "X = X_ohe\n",
    "\n",
    "#Transform categorial data(Sex) into new boolean attributes\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import make_column_transformer\n",
    "# Set the transformer data type\n",
    "transf_dtype = np.int32\n",
    "\n",
    "# Specific columns dataframe to one hot encoding , add new columns drop old column\n",
    "# Instantiate the encoder only on needed columns and perform `fit_transform`\n",
    "encoder = make_column_transformer((OneHotEncoder(handle_unknown = 'ignore', sparse = False, dtype = transf_dtype), ['Sex']), remainder='passthrough')\n",
    "transformed = encoder.fit_transform(X)\n",
    "\n",
    "#Since `fit_transform` returns an `ndarray`, but a dataframe is needed\n",
    "# Column Sex has M,F,I value\n",
    "encX = pd.DataFrame(transformed, columns = encoder.get_feature_names())\n",
    "encX.rename(columns = {'onehotencoder__x0_F':'Female', 'onehotencoder__x0_I':'Indefinite', 'onehotencoder__x0_M':'Male'}, inplace = True)                   #renaming of the freshly added columns\n",
    "encX\n",
    "\n",
    "# machineLearning-03c-prepr-dissim.pdf 26/71\n",
    "# OrdinalEncoder (from Ordinal to Numerical )\n",
    "# In order to do a classification, our column_to_convert column has to become numerical\n",
    "# from 1 column to 1 column of range -1 to +1\n",
    "encoder = OrdinalEncoder()\n",
    "df['column_to_convert'] = encoder.fit_transform(df['column_to_convert'].values.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_Ge8beN8uqIZ"
   },
   "source": [
    "### Snippets utili (Liste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "N-kBrA3guqIZ"
   },
   "outputs": [],
   "source": [
    "# Remove an item (target) from a list\n",
    "list_name.remove(target)\n",
    "\n",
    "# Sort the values\n",
    "list_name.sort()\n",
    "\n",
    "# Append an item (target) to a list (put it last)\n",
    "list_name.append(target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iCUYkICLuqIa"
   },
   "source": [
    "## 2. Classificazione"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XcZFXGs1uqIa"
   },
   "source": [
    "### Divisione in X e y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AhnB1sbauqIa"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df.drop(target, axis = 1)\n",
    "y = df[target]\n",
    "\n",
    "Xtrain, Xtest, ytrain, ytest = train_test_split(X, y,train_size = 2/3, random_state = random_state)\n",
    "print(f\"We have {Xtrain.shape[0]} items in our training set\")\n",
    "print(f\"We have {Xtest.shape[0]} items in our test set\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BjPqPgMmuqIa"
   },
   "source": [
    "### Train Validation Test (ulteriore divisione del train per ottenere validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bGjocOsHuqIa"
   },
   "outputs": [],
   "source": [
    "Xtrain2, Xval, ytrain2, yval = train_test_split(Xtrain, ytrain, random_state= random_state)\n",
    "\n",
    "print(f\"We have {Xtrain2.shape[0]} items in our train set\")\n",
    "print(f\"We have {Xval.shape[0]} items in our validation set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6DZwJ4GguqIb"
   },
   "outputs": [],
   "source": [
    "# With validation  train 50% , test 25% , val 25%\n",
    "Xtrain, Xtest1, ytrain, ytest1 = train_test_split(     X,      y,train_size = 1/2, random_state = random_state)\n",
    "Xtest, Xval, ytest, yval = train_test_split(Xtest1, ytest1,train_size = 1/2, random_state = random_state)\n",
    "print(f\"We have {Xtrain.shape[0]} items in our training set\")\n",
    "print(f\"We have {Xtest.shape[0]} items in our test set\")\n",
    "print(f\"We have {Xval.shape[0]} items in our validation set\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4uMmHNbwuqIb"
   },
   "source": [
    "Now we can save the depth of the tree (DecisionTree) with default hyperparameters. This way, we can vary the depths in order to see what is the best fit for our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YRxejbAsuqIb"
   },
   "outputs": [],
   "source": [
    "# dt comes from a previous creation of a DecisionTree Classifier\n",
    "\n",
    "default_depth = dt.tree_.max_depth\n",
    "range_depth = range(1, default_depth+1)\n",
    "\n",
    "#use accuracy as method of evaluation\n",
    "scores= []\n",
    "for i in range_depth:\n",
    "    current_model = DecisionTreeClassifier(criterion=\"entropy\", max_depth=i, random_state=random_state)\n",
    "\n",
    "    current_model.fit(Xtrain2,ytrain2)\n",
    "    yval_predicted = current_model.predict(Xval)\n",
    "    scores.append([i, accuracy_score(yval, yval_predicted)*100])\n",
    "\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "km0Ygi0wuqIb"
   },
   "source": [
    "We now have a look at the accuracy scores that we obtained in the previous step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Sfmko_OJuqIc"
   },
   "outputs": [],
   "source": [
    "#now we insert the scores in a dataframe to get the best parameters easily\n",
    "score_df = pd.DataFrame(data=scores, columns=[\"max_depth\", \"accuracy_score\"])\n",
    "#order dataframe to get best accuracy score\n",
    "score_df = score_df.sort_values(by=[\"accuracy_score\"], ascending=False)\n",
    "score_df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jDq6xBduuqIc"
   },
   "source": [
    "### DecisionTree Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L1nC8rMEuqIc"
   },
   "source": [
    "#### i. Algoritmo generico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LxOMl5KGuqIc"
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Instantiate the DecisionTree Classifier\n",
    "dt = DecisionTreeClassifier(random_state = random_state)\n",
    "\n",
    "# Fit it to the training data\n",
    "dt.fit(Xtrain, ytrain)\n",
    "\n",
    "# Try to predict training data\n",
    "dt_train_prediction = dt.predict(Xtrain)\n",
    "\n",
    "# Try to predict test data\n",
    "dt_test_prediction = dt.predict(Xtest)\n",
    "\n",
    "# Compute the accuracy score for the predictions\n",
    "dt_train_accuracy = accuracy_score(ytrain, dt_train_prediction) * 100\n",
    "dt_test_accuracy = accuracy_score(ytest, dt_test_prediction) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Knk2xyTUuqId"
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "def get_accuracy(estimator,Xtrain,Xtest,ytrain,ytest):\n",
    "    # Fit it to the training data\n",
    "    estimator.fit(Xtrain, ytrain)\n",
    "\n",
    "    # Try to predict training data\n",
    "    train_prediction = estimator.predict(Xtrain)\n",
    "\n",
    "    # Try to predict test data\n",
    "    test_prediction = estimator.predict(Xtest)\n",
    "\n",
    "    # Compute the accuracy score for the predictions\n",
    "    train_accuracy = accuracy_score(ytrain, train_prediction) * 100\n",
    "    test_accuracy = accuracy_score(ytest, test_prediction) * 100\n",
    "\n",
    "    return train_accuracy,test_accuracy\n",
    "\n",
    "# Usage\n",
    "# Instantiate the DecisionTree Classifier\n",
    "dt = DecisionTreeClassifier(random_state = random_state)\n",
    "# Instantiate the Linear Perceptron\n",
    "lp = Perceptron(random_state = random_state)\n",
    "# Instantiate the KNN Classifier\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "train_accuracy,test_accuracy = get_accuracy(dt,Xtrain,Xtest,ytrain,ytest)\n",
    "\n",
    "print(f\"The decision tree had an accuracy of {train_accuracy:.2f} on the training set and {test_accuracy:.2f} on the test set\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PC88YYHDuqId"
   },
   "source": [
    "#### ii. Ricerca dei migliori parametri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PKSTPp-OuqId"
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Instantiate the DecisionTree Classifier\n",
    "dt = DecisionTreeClassifier(random_state = random_state)\n",
    "\n",
    "# Fit it to the training data\n",
    "dt.fit(Xtrain, ytrain)\n",
    "\n",
    "# Create the range of parameters to try during cross-validation\n",
    "dt_depths = range(1, dt.get_depth() + 1)\n",
    "\n",
    "# We will use GridSearchCV to perform cross-validation\n",
    "# we need to create the parameter list in a specific way\n",
    "# for it to work\n",
    "dt_params = [{'max_depth': list(dt_depths), 'random_state': [random_state]}]\n",
    "\n",
    "# Scoring\n",
    "# https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
    "scoring = 'accuracy'\n",
    "\n",
    "# Instantiate GridSearchCV\n",
    "dt_gs = GridSearchCV(   dt,\n",
    "                        dt_params,\n",
    "                        cv=5,\n",
    "                        scoring=scoring,\n",
    "                        return_train_score = False,\n",
    "                        n_jobs = 2,\n",
    "                    )\n",
    "\n",
    "# Fit it to the training data\n",
    "dt_gs.fit(Xtrain, ytrain)\n",
    "\n",
    "# Print the best parameters found\n",
    "print(f\"The best parameter found for the Decision Tree was {dt_gs.best_params_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qIhl1i3_uqIe"
   },
   "outputs": [],
   "source": [
    "dt = DecisionTreeClassifier(max_depth = dt_gs.best_params_[\"max_depth\"], random_state = random_state)\n",
    "dt.fit(Xtrain, ytrain)\n",
    "\n",
    "# Predict the test set in order to be able to compute the metrics later on\n",
    "dt_ypred = dt.predict(Xtest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OCzQddWpbbgi"
   },
   "source": [
    "#### ii.1 Ricerca dei migliori parametri con una funzione"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3Tn6aNc2bl0x"
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "def get_best_hyperparameter_decision_tree(random_state,X, y,scoring):\n",
    "    # Instantiate the DecisionTree Classifier\n",
    "    estimator = DecisionTreeClassifier(random_state = random_state)\n",
    "\n",
    "    # Fit it to the training data\n",
    "    estimator.fit(X, y)\n",
    "\n",
    "    # Create the range of parameters to try during cross-validation\n",
    "    estimator_depths = range(1, estimator.get_depth() + 1)\n",
    "\n",
    "    # We will use GridSearchCV to perform cross-validation\n",
    "    # we need to create the parameter list in a specific way\n",
    "    # for it to work\n",
    "    estimator_params = [{'max_depth': list(estimator_depths), 'random_state': [random_state]}]\n",
    "\n",
    "    # Instantiate GridSearchCV\n",
    "    estimator_gs = GridSearchCV(   estimator,\n",
    "                                    estimator_params,\n",
    "                                    cv=5,\n",
    "                                    scoring=scoring,\n",
    "                                    return_train_score = False,\n",
    "                                    n_jobs = 2,\n",
    "                        )\n",
    "\n",
    "    # Fit it to the training data\n",
    "    estimator_gs.fit(X, y)\n",
    "\n",
    "    # Print the best parameters found\n",
    "    print(f\"The best parameter found for the Decision Tree was {estimator_gs.best_params_}\")\n",
    "    return estimator_gs.best_params_['max_depth']\n",
    "\n",
    "# USAGE\n",
    "scoring = 'accuracy'\n",
    "best_parameter = get_best_hyperparameter_decision_tree(random_state,Xtrain, ytrain,scoring)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "43R9lI_HuqIe"
   },
   "source": [
    "#### iii. Calcolo Accuracy, Confusion Matrix e Classification Report con parametri migliori"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d8N9Q_iJcMdT"
   },
   "outputs": [],
   "source": [
    "dt = DecisionTreeClassifier(max_depth = dt_best_parameter, random_state = random_state)\n",
    "dt.fit(Xtrain, ytrain)\n",
    "\n",
    "# Predict the test set in order to be able to compute the metrics later on\n",
    "dt_ypred = dt.predict(Xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0CuQU87luqIe"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "# Accuracy score\n",
    "dt_accuracy = accuracy_score(ytest, dt_ypred) * 100\n",
    "print(f\"The accuracy score for the Decision Tree with the optimized hyperparameters was: {dt_accuracy:.2f}%\")\n",
    "\n",
    "# Confusion matrix\n",
    "print(\"The confusion matrix is:\")\n",
    "cm_DT = confusion_matrix(ytest,dt_ypred)\n",
    "CMD = ConfusionMatrixDisplay(cm_DT)\n",
    "CMD.plot()\n",
    "\n",
    "# Classification Report\n",
    "print(\"Classification report: \")\n",
    "print(classification_report(ytest, dt_ypred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8nWY13pouqIe"
   },
   "source": [
    "### K-nearest Neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hjyvRo9buqIe"
   },
   "source": [
    "#### i. Algoritmo generico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PshbUJu4uqIf"
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Instantiate the KNN Classifier\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "# Fit it to the training data\n",
    "knn.fit(Xtrain, ytrain)\n",
    "\n",
    "# Try to predict training data\n",
    "knn_train_prediction = knn.predict(Xtrain)\n",
    "\n",
    "# Try to predict test data\n",
    "knn_test_prediction = knn.predict(Xtest)\n",
    "\n",
    "# Compute the accuracy score for the predictions\n",
    "knn_train_accuracy = accuracy_score(ytrain, knn_train_prediction) * 100\n",
    "knn_test_accuracy = accuracy_score(ytest, knn_test_prediction) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BYFLT7T7uqIf"
   },
   "source": [
    "#### ii. Ricerca dei migliori parametri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zu8fuF5OuqIg"
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Instantiate the KNN Classifier\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "# Create the range of parameters to try during cross-validation\n",
    "knn_neighbors = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "\n",
    "# We will use GridSearchCV to perform cross-validation\n",
    "# we need to create the parameter list in a specific way\n",
    "# for it to work\n",
    "knn_params = [{'n_neighbors': knn_neighbors}]\n",
    "\n",
    "# Instantiate GridSearchCV\n",
    "knn_gs = GridSearchCV(  knn,\n",
    "                        knn_params,\n",
    "                        cv=5,\n",
    "                        scoring='accuracy',             # [CAMBIARE]\n",
    "                        return_train_score = False,\n",
    "                        n_jobs = 2,\n",
    "                )\n",
    "\n",
    "# Fit it to the training data\n",
    "knn_gs.fit(Xtrain, ytrain)\n",
    "\n",
    "# Print the best parameters found\n",
    "print(f\"The best parameter found for the Nearest Neighbors was {knn_gs.best_params_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lmyyBKlvzudd"
   },
   "source": [
    "#### ii.1 Ricerca dei parametri migliori con funzione"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tEgYA8Ca0FCk"
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "def get_best_hyperparameter_nearest_neighbors(X, y,scoring):\n",
    "    # Instantiate the KNN Classifier\n",
    "    knn = KNeighborsClassifier()\n",
    "\n",
    "    # Create the range of parameters to try during cross-validation\n",
    "    knn_neighbors = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "\n",
    "    # We will use GridSearchCV to perform cross-validation\n",
    "    # we need to create the parameter list in a specific way\n",
    "    # for it to work\n",
    "    knn_params = [{'n_neighbors': knn_neighbors}]\n",
    "\n",
    "    # Instantiate GridSearchCV\n",
    "    knn_gs = GridSearchCV(  knn,\n",
    "                            knn_params,\n",
    "                            cv=5,\n",
    "                            scoring=scoring,\n",
    "                            return_train_score = False,\n",
    "                            n_jobs = 2,\n",
    "                    )\n",
    "\n",
    "    # Fit it to the training data\n",
    "    knn_gs.fit(Xtrain, ytrain)\n",
    "\n",
    "    # Print the best parameters found\n",
    "    print(f\"The best parameter found for the Nearest Neighbors was {knn_gs.best_params_}\")\n",
    "    return knn_gs.best_params_['n_neighbors']\n",
    "\n",
    "# USAGE\n",
    "scoring = 'accuracy'\n",
    "best_parameter = get_best_hyperparameter_nearest_neighbors(Xtrain, ytrain,scoring)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UCCTyMUruqIh"
   },
   "outputs": [],
   "source": [
    "# Instantiate the KNN Classifier\n",
    "knn = KNeighborsClassifier(n_neighbors = 4)\n",
    "knn.fit(Xtrain, ytrain)\n",
    "\n",
    "# Predict the test set in order to be able to compute the metrics later on\n",
    "knn_ypred = knn.predict(Xtest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KoUiJpTOuqIh"
   },
   "source": [
    "#### iii. Calcolo Accuracy, Confusion Matrix e Classification Report con parametri migliori"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0s_j28qRuqIh"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "# Accuracy score\n",
    "knn_accuracy = accuracy_score(ytest, knn_ypred) * 100\n",
    "print(f\"The accuracy score for the Nearest Neighbors with the optimized hyperparameters was: {knn_accuracy:.2f}%\")\n",
    "\n",
    "# Confusion matrix\n",
    "print(\"The confusion matrix is:\")\n",
    "cm_KNN = confusion_matrix(ytest,knn_ypred)\n",
    "CMD = ConfusionMatrixDisplay(cm_KNN)\n",
    "CMD.plot()\n",
    "\n",
    "# Classification Report\n",
    "print(\"Classification report: \")\n",
    "print(classification_report(ytest, knn_ypred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j5tfB6QCuqIh"
   },
   "outputs": [],
   "source": [
    "# Model labels to facilitate iterations\n",
    "model_lbls = ['dt', 'lp', 'knn']\n",
    "# We will evaluate classification via the precision metric\n",
    "score = 'precision'\n",
    "# Parameters for each classifier\n",
    "tuned_param_dt = [{'max_depth': list(range(1,dt.get_depth() + 1)),'random_state': [random_state]}]\n",
    "tuned_param_lp = [{'early_stopping': [True], 'random_state': [random_state]}]\n",
    "tuned_param_knn =[{'n_neighbors': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]}]\n",
    "# set the models to be fitted specifying name, estimator and parameter structure\n",
    "models = {\n",
    "            'dt':   {\n",
    "                        'name': 'Decision Tree ',\n",
    "                        'estimator': DecisionTreeClassifier(),\n",
    "                        'param': tuned_param_dt,\n",
    "                    },\n",
    "            'lp':   {\n",
    "                        'name': 'Linear Perceptron ',\n",
    "                        'estimator': Perceptron(),\n",
    "                        'param': tuned_param_lp,\n",
    "                    },\n",
    "            'knn':\n",
    "                    {   'name': 'K Nearest Neighbor ',\n",
    "                        'estimator': KNeighborsClassifier(),\n",
    "                        'param': tuned_param_knn\n",
    "                    }\n",
    "        }\n",
    "\n",
    "def get_accuracy_and_confusionmatrix(estimator,Xtrain, ytrain,ytest):\n",
    "    estimator.fit(Xtrain, ytrain)\n",
    "    ypred = estimator.predict(Xtest)\n",
    "    accuracy = accuracy_score(ytest, ypred) * 100\n",
    "    cm = confusion_matrix(ytest, ypred)\n",
    "    return accuracy,cm\n",
    "\n",
    "\n",
    "def print_accuracy_and_confusionmatrix(accuracy,cm,model_name):\n",
    "    print(f\"The accuracy score for the {model_name} with the optimized hyperparameters was: {accuracy:.2f}%\")\n",
    "\n",
    "    # Confusion matrix\n",
    "    print(\"The confusion matrix is:\")\n",
    "    print(cm)\n",
    "\n",
    "accuracies = []\n",
    "cms =[]\n",
    "model_names = []\n",
    "\n",
    "for m in model_lbls:\n",
    "    estimator = models[m]['estimator']\n",
    "    model_name = models[m]['name']\n",
    "    accuracy,cm = get_accuracy_and_confusionmatrix(estimator,Xtrain, ytrain,ytest)\n",
    "    print_accuracy_and_confusionmatrix(accuracy,cm,model_name)\n",
    "    accuracies.append(accuracy)\n",
    "    cms.append(cm)\n",
    "    model_names.append(model_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L-yFX-rkuqIi"
   },
   "source": [
    "### Linear Perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YF89bKO_uqIi"
   },
   "source": [
    "#### i. Algoritmo generico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QDOk5kf8uqIi"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Perceptron\n",
    "\n",
    "# Instantiate the Linear Perceptron\n",
    "lp = Perceptron(random_state = random_state)\n",
    "\n",
    "# Fit it to the training data\n",
    "lp.fit(Xtrain, ytrain)\n",
    "\n",
    "# Try to predict training data\n",
    "lp_train_prediction = lp.predict(Xtrain)\n",
    "\n",
    "# Try to predict test data\n",
    "lp_test_prediction = lp.predict(Xtest)\n",
    "\n",
    "# Compute the accuracy score for the predictions\n",
    "lp_train_accuracy = accuracy_score(ytrain, lp_train_prediction) * 100\n",
    "lp_test_accuracy = accuracy_score(ytest, lp_test_prediction) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "50I08LYFuqIj"
   },
   "source": [
    "#### iii. Calcolo Accuracy, Confusion Matrix e Classification Report con parametri migliori"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6c2bHsrQuqIj"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "# Accuracy score\n",
    "lp_accuracy = accuracy_score(ytest, lp_test_prediction) * 100\n",
    "print(f\"The accuracy score for the Decision Tree with the optimized hyperparameters was: {lp_accuracy:.2f}%\")\n",
    "\n",
    "# Confusion matrix\n",
    "print(\"The confusion matrix is:\")\n",
    "cm_LP = confusion_matrix(ytest,lp_test_prediction)\n",
    "CMD = ConfusionMatrixDisplay(cm_LP)\n",
    "CMD.plot()\n",
    "\n",
    "# Classification report\n",
    "print(\"Classification report: \")\n",
    "print(classification_report(ytest, lp_test_prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g-rUqkF6uqIj"
   },
   "source": [
    "## 3. Confronto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qNSmdY-cuqIj"
   },
   "source": [
    "### Performance con migliori parametri e matrici di confusione"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oh5IizO-uqIk"
   },
   "outputs": [],
   "source": [
    "#Codice adattato da marco lorenzo per stampa ridotta e sistemata; (non salva precision e recall in strutture dati ma li stampa alla fine)\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "model_lbls = [\n",
    "              'dt',\n",
    "              'lp',\n",
    "             'knn'\n",
    "            ]\n",
    "\n",
    "# Set the parameters by cross-validation [CAMBIARE PARAMETRI]\n",
    "\n",
    "models = {\n",
    "    'dt': {'name': 'Decision Tree       ',\n",
    "           'estimator': DecisionTreeClassifier(max_depth = 5, random_state = random_state),\n",
    "          },\n",
    "    'lp': {'name': 'Linear Perceptron   ',\n",
    "           'estimator': Perceptron(early_stopping=True, random_state=random_state),\n",
    "          },\n",
    "    'knn':{'name': 'K Nearest Neighbor ',\n",
    "           'estimator': KNeighborsClassifier(n_neighbors=5),\n",
    "       }\n",
    "}\n",
    "\n",
    "dictModel_pred = {}\n",
    "dictModel_accuracy = {}\n",
    "dictModel_cm = {}\n",
    "\n",
    "\n",
    "def multipleClassifiers(model):\n",
    "    model.fit(Xtrain, ytrain)\n",
    "    model_pred = model.predict(Xtest)\n",
    "    model_accuracy = accuracy_score(ytest, model_pred) * 100\n",
    "    model_cm = confusion_matrix(ytest, model_pred)\n",
    "\n",
    "    dictModel_pred[model] = model_pred\n",
    "    dictModel_accuracy[model] = model_accuracy\n",
    "    dictModel_cm[model] = model_cm\n",
    "\n",
    "\n",
    "for model_lb in model_lbls:\n",
    "    model = models[model_lb][\"estimator\"]\n",
    "    multipleClassifiers(model)\n",
    "    print(\"\\n\"+str(model)+\":\")\n",
    "    print(\"Accuracy: \"+str(dictModel_accuracy[model]))\n",
    "    print(\"Confusion matrix: \")\n",
    "    print(dictModel_cm[model])\n",
    "    print(\"Classification report: \")\n",
    "    print(classification_report(ytest, dictModel_pred[model]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KPwkdJ7MuqIk"
   },
   "source": [
    "### Performance con migliori parametri e matrici di confusione V2 : a more generalized solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2q0A0kbMuqIk"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "# Model labels to facilitate iterations\n",
    "model_lbls = ['dt','lp','knn']\n",
    "\n",
    "# set the models to be fitted specifying name, estimator and parameter structure\n",
    "models = {\n",
    "            'dt':   {\n",
    "                        'name': 'Decision Tree ',\n",
    "                        'estimator': DecisionTreeClassifier()\n",
    "                    },\n",
    "            'lp':   {\n",
    "                        'name': 'Linear Perceptron   ',\n",
    "                        'estimator': Perceptron(early_stopping=True, random_state=random_state)\n",
    "                    },\n",
    "            'knn':\n",
    "                    {   'name': 'K Nearest Neighbor ',\n",
    "                        'estimator': KNeighborsClassifier()\n",
    "                    }\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pFjHi72YuqIl"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "scoring = 'accuracy'\n",
    "\n",
    "for model_name in model_lbls:\n",
    "    estimator = models[model_name]['estimator']\n",
    "    model_name_extended = models[model_name]['name']\n",
    "\n",
    "    if model_name == 'dt' :\n",
    "        # Fit it to the training data\n",
    "        estimator.fit(Xtrain, ytrain)\n",
    "        model_params = [{'max_depth': list(range(1,estimator.get_depth() + 1)),'random_state': [random_state]}]\n",
    "\n",
    "    if model_name == 'lp' :\n",
    "         model_params = [{'random_state': [random_state]}]\n",
    "\n",
    "    if model_name == 'knn' :\n",
    "         model_params = [{'n_neighbors': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]}]\n",
    "\n",
    "    # Instantiate GridSearchCV\n",
    "    model_gs = GridSearchCV(estimator,\n",
    "                            model_params,\n",
    "                            cv=5,\n",
    "                            scoring=scoring,\n",
    "                            return_train_score = False,\n",
    "                            n_jobs = 2,\n",
    "                    )\n",
    "\n",
    "    # Fit it to the training data\n",
    "    model_gs.fit(Xtrain, ytrain)\n",
    "\n",
    "    # Print the best parameters found\n",
    "    print(f\"The best parameter found for the {model_name_extended} was {model_gs.best_params_}\")\n",
    "\n",
    "    if model_name == 'dt' :\n",
    "        # Instantiate the Deccision Tree Classifier\n",
    "        estimator = DecisionTreeClassifier(max_depth = model_gs.best_params_[\"max_depth\"], random_state = random_state)\n",
    "\n",
    "    if model_name == 'lp' :\n",
    "        # Instantiate the Perceptron Classifier\n",
    "        estimator = Perceptron(random_state = random_state)\n",
    "\n",
    "    if model_name == 'knn' :\n",
    "        # Instantiate the KNN Classifier\n",
    "        estimator = KNeighborsClassifier(n_neighbors = model_gs.best_params_[\"n_neighbors\"])\n",
    "\n",
    "\n",
    "    estimator.fit(Xtrain, ytrain)\n",
    "\n",
    "    # Predict the test set in order to be able to compute the metrics later on\n",
    "    model_ypred = estimator.predict(Xtest)\n",
    "\n",
    "    # Classification Report\n",
    "    print(\"Classification report: \")\n",
    "    print(classification_report(ytest, model_ypred))\n",
    "\n",
    "    # Confusion matrix\n",
    "    cm_model = confusion_matrix(ytest,model_ypred)\n",
    "    CMD = ConfusionMatrixDisplay(cm_model)\n",
    "    CMD.plot()\n",
    "    CMD.ax_.set_title(f\"The confusion matrix for {model_name_extended}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z__5EAOdPZ1n"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "scoring = 'accuracy'\n",
    "\n",
    "# Model labels to facilitate iterations\n",
    "model_lbls = ['dt','lp','knn']\n",
    "\n",
    "# set the models to be fitted specifying name, estimator and parameter structure\n",
    "models = {\n",
    "            'dt':   {\n",
    "                        'name': 'Decision Tree ',\n",
    "                        'estimator': DecisionTreeClassifier(),\n",
    "                        'accuracy' : 0\n",
    "                    },\n",
    "            'lp':   {\n",
    "                        'name': 'Linear Perceptron   ',\n",
    "                        'estimator': Perceptron(early_stopping=True, random_state=random_state),\n",
    "                        'accuracy' : 0\n",
    "                    },\n",
    "            'knn':\n",
    "                    {   'name': 'K Nearest Neighbor ',\n",
    "                        'estimator': KNeighborsClassifier(),\n",
    "                        'accuracy' : 0\n",
    "                    }\n",
    "        }\n",
    "\n",
    "for model_name in model_lbls:\n",
    "    estimator = models[model_name]['estimator']\n",
    "    model_name_extended = models[model_name]['name']\n",
    "\n",
    "    if model_name == 'dt' :\n",
    "        # Fit it to the training data\n",
    "        estimator.fit(Xtrain, ytrain)\n",
    "        model_params = [{'max_depth': list(range(1,estimator.get_depth() + 1)),'random_state': [random_state]}]\n",
    "\n",
    "    if model_name == 'lp' :\n",
    "         model_params = [{'random_state': [random_state]}]\n",
    "\n",
    "    if model_name == 'knn' :\n",
    "         model_params = [{'n_neighbors': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]}]\n",
    "\n",
    "\n",
    "    # 5. For each classification method find the best parameter setting with cross validation on the training set\n",
    "\n",
    "    # Instantiate GridSearchCV\n",
    "    model_gs = GridSearchCV(estimator,\n",
    "                            model_params,\n",
    "                            cv=5,\n",
    "                            scoring=scoring,\n",
    "                            return_train_score = False,\n",
    "                            n_jobs = 2,\n",
    "                    )\n",
    "\n",
    "    # Fit it to the training data\n",
    "    model_gs.fit(Xtrain, ytrain)\n",
    "\n",
    "    # Print the best parameters found\n",
    "    print(f\"The best parameter found for the {model_name_extended} was {model_gs.best_params_}\")\n",
    "\n",
    "    if model_name == 'dt' :\n",
    "        # Instantiate the Deccision Tree Classifier\n",
    "        estimator = DecisionTreeClassifier(max_depth = model_gs.best_params_[\"max_depth\"], random_state = random_state)\n",
    "\n",
    "    if model_name == 'lp' :\n",
    "        # Instantiate the Perceptron Classifier\n",
    "        estimator = Perceptron(random_state = random_state)\n",
    "\n",
    "    if model_name == 'knn' :\n",
    "        # Instantiate the KNN Classifier\n",
    "        estimator = KNeighborsClassifier(n_neighbors = model_gs.best_params_[\"n_neighbors\"])\n",
    "\n",
    "    estimator.fit(Xtrain, ytrain)\n",
    "\n",
    "    # 6. For each classification method compute the accuracy and the confusion matrix on the test set\n",
    "\n",
    "    # Predict the test set in order to be able to compute the metrics later on\n",
    "    model_ypred = estimator.predict(Xtest)\n",
    "\n",
    "    # Classification Report\n",
    "    print(\"Classification report: \")\n",
    "    print(classification_report(ytest, model_ypred))\n",
    "\n",
    "\n",
    "    if model_name == 'dt' :\n",
    "        # Accuracy of the Decision Tree Classifier\n",
    "\n",
    "        models[model_name]['accuracy'] = accuracy_score(ytest, model_ypred) * 100\n",
    "\n",
    "    if model_name == 'lp' :\n",
    "        # Accuracy of the Perceptron Classifier\n",
    "        models[model_name]['accuracy'] = accuracy_score(ytest, model_ypred) * 100\n",
    "\n",
    "    if model_name == 'knn' :\n",
    "        # Accuracy of the KNN Classifier\n",
    "        models[model_name]['accuracy'] = accuracy_score(ytest, model_ypred) * 100\n",
    "\n",
    "    # Confusion matrix\n",
    "    cm_model = confusion_matrix(ytest,model_ypred)\n",
    "    CMD = ConfusionMatrixDisplay(cm_model)\n",
    "    CMD.plot()\n",
    "    CMD.ax_.set_title(f\"The confusion matrix for {model_name_extended}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NYMznqU1uqIl"
   },
   "source": [
    "### Grafico di confronto delle Accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kJkPSywUuqIl"
   },
   "outputs": [],
   "source": [
    "# Codice sui tre modelli [MODIFICARE DI CONSEGUENZA]\n",
    "classifier_list = ['Decision Tree', 'Linear Perceptron', 'K-Nearest Neighbors']\n",
    "acc_list = [dt_accuracy, lp_accuracy, knn_accuracy]\n",
    "plt.title('Accuracy of each classifier')\n",
    "plt.bar(classifier_list, acc_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K9UGLQh5uqIm"
   },
   "source": [
    "## 4. Trasformazioni dei valori"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i0JHb6vUuqIm"
   },
   "source": [
    "### Miglioramento dei risultati (operazione Logaritmica)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZFUAW3oyuqIm"
   },
   "outputs": [],
   "source": [
    "# Logarithmic transformation\n",
    "for column in X.columns:\n",
    "\n",
    "    # We don't want to transform columns with values\n",
    "    # Lower than or equal to zero\n",
    "    if (X[column] <= 0).any().any():\n",
    "        continue\n",
    "\n",
    "    X[column] = np.log(X[column])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Eje_p8anuqIm"
   },
   "source": [
    "### MinMax Scaler: trasformazione tutti valori in un range da 0 a 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O_9YnonTuqIm"
   },
   "outputs": [],
   "source": [
    "# remap on the 0:1 range with MinMaxScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "mms = MinMaxScaler()\n",
    "X = pd.DataFrame(mms.fit_transform(X), columns = X.columns)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HmSKsNGHuqIn"
   },
   "source": [
    "### Square Root transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gXxjPk8IuqIn"
   },
   "outputs": [],
   "source": [
    "# square root transformation - the first two columns are not transformed\n",
    "from math import sqrt\n",
    "\n",
    "X_sqrt = pd.concat([X.iloc[:,:2],X.iloc[:,2:].applymap(sqrt)],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i23N0-FzuqIn"
   },
   "source": [
    "### MaxDiag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "98CU-e3quqIo"
   },
   "outputs": [],
   "source": [
    "# Professor function\n",
    "from max_diag import max_diag\n",
    "\n",
    "# Apply on a confusion matrix\n",
    "cm_km = max_diag(cm)\n",
    "CMD = ConfusionMatrixDisplay(cm_km)\n",
    "CMD.plot()\n",
    "\n",
    "# To see why it is useful\n",
    "help(max_diag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1zTKt3ptuqIo"
   },
   "source": [
    "## 4. Grafici"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-0HhbULnuqIo"
   },
   "source": [
    "### 4.1 scatterplot good/bad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "F3KfL3BtuqIo"
   },
   "outputs": [],
   "source": [
    "# X all attributes column\n",
    "# y target column\n",
    "# focus1 and focus2 : column used to plot\n",
    "# estimator : example DecisionTreeClassifier\n",
    "def plot_scatterplot_prediction_good_bad(X,y,focus1,focus2,estimator):\n",
    "    column_prediction = 'y_test_predition'\n",
    "    y_test_predition = estimator.predict(X)\n",
    "    df_plot = pd.concat([X, y], axis=1)\n",
    "    df_plot[column_prediction] = y_test_predition\n",
    "    sns.scatterplot(x=focus1, y=focus2, data=df_plot, hue=column_prediction ,style = y == df_plot[column_prediction] )"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  },
  "vscode": {
   "interpreter": {
    "hash": "1873f118b511de53363c30a8f94ef950fb879bc21455477d7c0f6a051a0155e8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
