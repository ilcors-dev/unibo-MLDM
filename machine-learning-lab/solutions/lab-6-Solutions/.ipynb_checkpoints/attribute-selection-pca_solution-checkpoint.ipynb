{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In fase di perfezionamento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning lab - 05 - Data Reduction\n",
    "Source:\n",
    "- Tabular Playground Series - Jun 2021\n",
    "- https://www.kaggle.com/competitions/tabular-playground-series-jun-2021\n",
    "\n",
    "We have available two data files, `train.csv` and `test.csv`. The first one will be used to find the best classification models for some performance measures, the second one is unsupervised, we will make the predictions for it using the best model and save it into a new file.\n",
    "\n",
    "## Unsupervised attribute selection\n",
    "\n",
    "Workflow:\n",
    "\n",
    "1. load `train.csv` and do some exploration (the number of columns is a bit large, avoid using `pairplots`, it would be very slow and undreadable)\n",
    "2. cancel useless columns, if any, use as target the `target` column, separate predicting from target into `X_full` and `y`\n",
    "3. Try unsupervised attribute selection: use `PCA` to keep only the transformed features able to explain, cumulatively, 90% of the total variance\n",
    "4. store in X the remaining, transformed variables\n",
    "5. split the X and y data into __train__ and __test__; since the file is quite large, for a faster development use not more than 2000 rows for training, and the remaining for testing\n",
    "6. show two pie charts of the distribution of classes into `y_train` and `y_test` to verify if they are similar\n",
    "7. optimize with `GridSearchCV` DecistionTree and RandomForest, using two different measures: `accuracy` and `f1_macro`\n",
    "8. show the confusion matrices of the best model for `accuracy` and `f1_macro` and comment the differences\n",
    "9. For the final test, upload the file `test.csv`, apply the same data reduction applied to `train.csv`,\n",
    "10. make the prediction using the models previously optimized\n",
    "11. show the confusion matrices and comment the comparison with the ones previously generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "804a1e82",
   "metadata": {
    "id": "804a1e82"
   },
   "outputs": [],
   "source": [
    "#Tabular Playground Series - Jun 2021\n",
    "#https://www.kaggle.com/competitions/tabular-playground-series-jun-2021\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore') # uncomment this line to suppress warnings\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n",
    "from sklearn.metrics import classification_report, ConfusionMatrixDisplay\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "KMfku5eXOQcW",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KMfku5eXOQcW",
    "outputId": "7d0d4e59-8ca8-41c2-dda5-ee54b331a85d"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "P2BVtJnLOl1m",
   "metadata": {
    "id": "P2BVtJnLOl1m"
   },
   "outputs": [],
   "source": [
    "# google_drive_path = '/content/drive/MyDrive/Colab Notebooks/'\n",
    "file_path = \"./\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "okMNG7t2OYlB",
   "metadata": {
    "id": "okMNG7t2OYlB"
   },
   "outputs": [],
   "source": [
    "# !ls /content/drive/MyDrive/Colab\\ Notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "17a4a64d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "17a4a64d",
    "outputId": "37760241-4ab1-4fe7-8325-b3c8c0ef514b"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'lab5-data/train.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mseed(random_state) \u001b[38;5;66;03m# this sets the random sequence. Setting only this the repeatability is guaranteed\u001b[39;00m\n\u001b[1;32m      6\u001b[0m                              \u001b[38;5;66;03m# only if we re-execute the entire notebook\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m train_ds \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrain.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShape of the training data \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(train_ds\u001b[38;5;241m.\u001b[39mshape))\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/mypython/lib/python3.11/site-packages/pandas/io/parsers/readers.py:948\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    936\u001b[0m     dialect,\n\u001b[1;32m    937\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    944\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m    945\u001b[0m )\n\u001b[1;32m    946\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 948\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/mypython/lib/python3.11/site-packages/pandas/io/parsers/readers.py:611\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    608\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    610\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 611\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    613\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    614\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/mypython/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1448\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1445\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1447\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1448\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/mypython/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1705\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1703\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1704\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1705\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1706\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1707\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1708\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1709\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1710\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1711\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1712\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1713\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1714\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1715\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1716\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/mypython/lib/python3.11/site-packages/pandas/io/common.py:863\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    858\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    859\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    860\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    861\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    862\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 863\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    864\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    865\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    866\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    867\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    868\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    869\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    871\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    872\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'lab5-data/train.csv'"
     ]
    }
   ],
   "source": [
    "\n",
    "train_size = 0.01 # train size chosen to have a few tousands of elements\n",
    "cutoff_variance = .8 # the total amount of variance explained by the selected transformed features\n",
    "cv = 5\n",
    "random_state = 42\n",
    "np.random.seed(random_state) # this sets the random sequence. Setting only this the repeatability is guaranteed\n",
    "                             # only if we re-execute the entire notebook\n",
    "\n",
    "train_ds = pd.read_csv(file_path+'train.csv')\n",
    "\n",
    "print(\"Shape of the training data {}\".format(train_ds.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a69fcdf",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 412
    },
    "id": "9a69fcdf",
    "outputId": "2a1b9d8d-db9f-4a84-9d8b-6acac711ae46"
   },
   "outputs": [],
   "source": [
    "# show 10 random records\n",
    "train_ds.sample(n=10, axis=0, replace=False, random_state = random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0050d8f1",
   "metadata": {
    "id": "0050d8f1"
   },
   "outputs": [],
   "source": [
    "train_ds.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6679ce5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c6679ce5",
    "outputId": "d2e79a76-49ec-416b-e47a-7b031a5e6f4c"
   },
   "outputs": [],
   "source": [
    "train_ds.nunique().sort_values(ascending=False)[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b5892fd",
   "metadata": {
    "id": "8b5892fd"
   },
   "outputs": [],
   "source": [
    "# train_ds['feature_15'].sort_values(ascending=False)[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f669a80",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8f669a80",
    "outputId": "89a4714c-67e8-4eda-cedd-de6a87272964"
   },
   "outputs": [],
   "source": [
    "target = 'target'\n",
    "classes = train_ds[target].unique()\n",
    "classes.sort()\n",
    "print(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "398f513e",
   "metadata": {
    "id": "398f513e"
   },
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "y = le.fit_transform(train_ds[target])\n",
    "X_full = train_ds.drop(['id', target], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33013a1f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 255
    },
    "id": "33013a1f",
    "outputId": "144dd82c-f257-409b-d30a-d1a972675ff0"
   },
   "outputs": [],
   "source": [
    "X_full.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fbd4ae2",
   "metadata": {
    "id": "0fbd4ae2"
   },
   "outputs": [],
   "source": [
    "model_lbls = ['dt' # decision tree\n",
    "             #,'nb' # gaussian naive bayes\n",
    "             ,'rf'   # random forest\n",
    "             #,'lp'   # linear perceptron\n",
    "             #,'svc'  # support vector\n",
    "             #,'knn'  # k nearest neighbours\n",
    "             #,'adb'  # adaboost\n",
    "            ]\n",
    "\n",
    "models = {\n",
    "    'dt': {'name': 'Decision Tree       ',\n",
    "           'estimator': DecisionTreeClassifier(random_state=random_state),\n",
    "           'param': [{'max_depth': [*range(1,20)],'class_weight':[None,'balanced']}],\n",
    "          },\n",
    "    'nb': {'name': 'Gaussian Naive Bayes',\n",
    "           'estimator': GaussianNB(),\n",
    "           'param': [{'var_smoothing': [10**exp for exp in range(-3,-12,-1)]}]\n",
    "          },\n",
    "    'lp': {'name': 'Linear Perceptron   ',\n",
    "           'estimator': Perceptron(random_state=random_state),\n",
    "           'param': [{'early_stopping': [True,False],'class_weight':[None,'balanced']}],\n",
    "          },\n",
    "    'svc':{'name': 'Support Vector      ',\n",
    "           'estimator': SVC(random_state=random_state),\n",
    "           'param': [{'kernel': ['rbf'],\n",
    "                    'gamma': [1e-3, 1e-4],\n",
    "                    'C': [1, 10, 100],\n",
    "                    },\n",
    "                    {'kernel': ['linear'],\n",
    "                     'C': [1, 10, 100],\n",
    "                    },\n",
    "                   ]\n",
    "          },\n",
    "    'knn':{'name': 'K Nearest Neighbor ',\n",
    "           'estimator': KNeighborsClassifier(),\n",
    "           'param': [{'n_neighbors': list(range(1,7))}]\n",
    "       },\n",
    "    'adb':{'name': 'AdaBoost           ',\n",
    "           'estimator': AdaBoostClassifier(random_state=random_state),\n",
    "           'param': [{'n_estimators':[20,30,40,50]\n",
    "                     ,'learning_rate':[0.5,0.75,1,1.25,1.5]}]\n",
    "          },\n",
    "    'rf': {'name': 'Random forest       ',\n",
    "           'estimator': RandomForestClassifier(random_state=random_state),\n",
    "           'param': [{\n",
    "                      # 'max_depth': [*range(4,30)]\n",
    "                      'max_depth': [*range(4,30,4)]\n",
    "                    #  ,'n_estimators':[*range(20,80,5)]\n",
    "                     ,'n_estimators':[*range(10,30,5)]\n",
    "                     ,'class_weight': [None,'balanced']\n",
    "                      }]\n",
    "          }\n",
    "\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e51a5dc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 453
    },
    "id": "1e51a5dc",
    "outputId": "97efa628-dc4d-42a5-c79e-c4bcf5b13b04"
   },
   "outputs": [],
   "source": [
    "pca = PCA()\n",
    "\n",
    "X_trans = pca.fit_transform(X_full)\n",
    "\n",
    "# print(pca.explained_variance_ratio_ )\n",
    "\n",
    "plt.plot(range(X_full.shape[1]), pca.explained_variance_ratio_);\n",
    "\n",
    "plt.xlabel('Columns')\n",
    "plt.ylabel('PCA Explained Variance Ratio')\n",
    "\n",
    "plt.xticks(rotation = 90)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "256539ef",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "256539ef",
    "outputId": "fb4561fb-b1e8-47dc-acff-fe0b1814e894"
   },
   "outputs": [],
   "source": [
    "explained_variances = pca.explained_variance_ratio_\n",
    "\n",
    "# Sort the explained variance ratios in descending order\n",
    "sorted_variances = sorted(explained_variances, reverse=True)\n",
    "\n",
    "\n",
    "# Calculate the cumulative sum of the explained variance ratios\n",
    "cumulative_variances = np.cumsum(sorted_variances)\n",
    "\n",
    "# Find the index i of the first principal component where the cumulative sum exceeds 0.05\n",
    "cutoff_index = np.argmax(cumulative_variances > cutoff_variance)\n",
    "print(\"Used the top {} transformed variables\".format(cutoff_index))\n",
    "\n",
    "# Keep the first i principal components and discard the rest\n",
    "X = pca.transform(X_full)[:, :cutoff_index+1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bd36e73",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6bd36e73",
    "outputId": "bce29b8f-f7df-4782-f6b6-df20f68d89ea"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y\n",
    "                                                    , train_size = train_size\n",
    "                                                    , random_state = random_state) # default Train 0.75- Test 0.25\n",
    "print(\"There are {} samples in the training dataset\".format(X_train.shape[0]))\n",
    "print(\"There are {} samples in the testing dataset\".format(X_test.shape[0]))\n",
    "print(\"Each sample has {} features\".format(X.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f39a29c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 262
    },
    "id": "6f39a29c",
    "outputId": "4e4dbd2a-7f5e-422d-8cf5-36261db21d31"
   },
   "outputs": [],
   "source": [
    "fig, (ax1,ax2) = plt.subplots(nrows=1, ncols=2)\n",
    "ax1.pie(np.unique(y_train, return_counts=True)[1], labels=np.unique(y_train, return_counts=True)[0]);\n",
    "ax1.set_title(\"Label distribution in Train\")\n",
    "ax2.pie(np.unique(y_test, return_counts=True)[1], labels=np.unique(y_test, return_counts=True)[0]);\n",
    "ax2.set_title(\"Label distribution in Test\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b750982",
   "metadata": {
    "id": "9b750982"
   },
   "outputs": [],
   "source": [
    "scorings = ['accuracy'\n",
    "            # ,'precision_macro'\n",
    "            # ,'recall_macro'\n",
    "            ,'f1_macro'\n",
    "            ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca8c6f24",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ca8c6f24",
    "outputId": "92ee3806-a1c1-415b-bf6b-e2a0ab901c23"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ParameterGrid\n",
    "trials = {lbl: len(list(ParameterGrid(models[lbl]['param']))) for lbl in model_lbls}\n",
    "trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f4cbfff",
   "metadata": {
    "id": "1f4cbfff"
   },
   "outputs": [],
   "source": [
    "clfs = []\n",
    "results = pd.DataFrame(columns=['scoring','model','best_params','accuracy','precision_macro','recall_macro','f1_macro'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1457a0e",
   "metadata": {
    "id": "c1457a0e"
   },
   "outputs": [],
   "source": [
    "for scoring in scorings:\n",
    "    for m in model_lbls:\n",
    "        clf = GridSearchCV(models[m]['estimator'], models[m]['param'], cv=cv,\n",
    "                           scoring = scoring,\n",
    "\n",
    "                           )\n",
    "        clf.fit(X_train, y_train)\n",
    "        clfs.append(clf)\n",
    "        y_true, y_pred = y_test, clf.predict(X_test)\n",
    "        # y_preds.append(y_pred)\n",
    "        cr = classification_report(y_true,y_pred, output_dict=True\n",
    "                                   , zero_division=1\n",
    "                                   )\n",
    "        results.loc[len(results)] = [scoring,models[m]['name'],clf.best_params_\n",
    "                                    # ,(clf.cv_results_['mean_fit_time'].sum()+clf.cv_results_['mean_score_time'].sum())*n_splits\n",
    "                                    ,cr['accuracy']\n",
    "                                    ,cr['macro avg']['precision']\n",
    "                                    ,cr['macro avg']['recall']\n",
    "                                    ,cr['macro avg']['f1-score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e72be9b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 241
    },
    "id": "0e72be9b",
    "outputId": "680f0fa7-b564-4038-95dc-785920e84184"
   },
   "outputs": [],
   "source": [
    "for score in scorings:\n",
    "    scoring_filter = score\n",
    "    display(results[results.scoring==scoring_filter]\\\n",
    "                .sort_values(by=scoring_filter,ascending=False)\\\n",
    "                .drop('scoring',axis=1)\\\n",
    "                .style.format(precision=3)\\\n",
    "                .set_caption('Results for scoring \"{}\"'.format(scoring_filter)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "914e8772",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 927
    },
    "id": "914e8772",
    "outputId": "99fe61c8-5a99-410b-89cc-1567b7febf17"
   },
   "outputs": [],
   "source": [
    "for score in scorings:\n",
    "    scoring_filter = score\n",
    "    # bests[score] = results.loc[results.scoring==scoring_filter,scoring_filter].idxmax(axis=0)\n",
    "    best_row = results.loc[results.scoring==scoring_filter,scoring_filter].idxmax(axis=0)\n",
    "    disp = ConfusionMatrixDisplay.from_estimator(X=X_test, y=y_test, estimator = clfs[best_row], normalize='true')\n",
    "    # disp.ax_.set_title(\"Best Model for {}: {}\".format(score,results.at[bests[score],'model']))\n",
    "    disp.ax_.set_title(\"Best Model for {}: {}\".format(score,results.at[best_row,'model']))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95756fec",
   "metadata": {
    "id": "95756fec"
   },
   "source": [
    "## Final step - make a prediction\n",
    "9. For the final test, upload the file `test.csv`, apply the same data reduction applied to `train.csv`\n",
    "    - in order to avoid confusion, we will call this dataset `u_test` (unsupervised)\n",
    "10. make the prediction using the models previously optimized\n",
    "    - train the best estimator for `f1_macro` with the __entire__ training set\n",
    "    - predict the target for `u_test` \n",
    "    - save a new file `test_predicted.csv` with the original test data and the predictions for the target\n",
    "11. show a pie chart of the distribution of classes in the predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "588c735f",
   "metadata": {
    "id": "588c735f"
   },
   "outputs": [],
   "source": [
    "u_test_ds = pd.read_csv(file_path+'test.csv').drop('id', axis=1)\n",
    "print(\"Shape of the test data {}\".format(u_test_ds.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_u_test = pca.transform(u_test_ds)[:, :cutoff_index+1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring_filter = 'f1_macro'\n",
    "best_row = results.loc[results.scoring==scoring_filter,scoring_filter].idxmax(axis=0)\n",
    "best_row\n",
    "# best_f1_macro = results.loc[best_row,'model']()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = clf.best_estimator_.predict(X_u_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1,ax2) = plt.subplots(nrows=1, ncols=2)\n",
    "ax1.pie(np.unique(y_train, return_counts=True)[1], labels=np.unique(y_train, return_counts=True)[0]);\n",
    "ax1.set_title(\"Label distribution in Train\")\n",
    "ax2.pie(np.unique(y, return_counts=True)[1], labels=np.unique(y, return_counts=True)[0]);\n",
    "ax2.set_title(\"Label distribution in Submission\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "mypython",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
